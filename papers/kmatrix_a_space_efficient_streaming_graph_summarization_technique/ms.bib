@inproceedings{mishra_modelling_2014,
	title = {Modelling of {Social} {Network} using {Graph} {Theoretical} {Approach}},
	abstract = {This paper describes the model of formation and properties of social network via a graph theoretical approach. The paper considers the interaction between different sets of people in a social network. It also describes the additional information about each individual in a network. We have also described the matrix representation of social network. The purpose of this paper is to review the graphical model of social networking. This paper is about how two persons are related to each other and how they can access each other‟s resources. A social network is a social structure made up of individuals (or organizations) called "nodes", which are tied(connected) by one or more specific types of interdependency, such as friendship, kinship, common interest, financial exchange, dislike, sexual relationships, or relationships of beliefs, knowledge or prestige.},
	author = {Mishra, Sweata and Borboruah, Rupam and Choudhury, Bharadwaj and Rakshit, Sandip},
	year = {2014},
	keywords = {Graph - visual representation, Social network, Graph theory, Graphical model, Interdependence, List of Code Lyoko episodes, Matrix representation, Social structure, The Matrix}
}

@article{ahmat_graph_nodate,
	title = {Graph {Theory} and {Optimization} {Problems} for {Very} {Large} {Networks}},
	abstract = {Graph theory provides a primary tool for analyzing and designing computer communication networks. In the past few decades, Graph theory has been used to study various types of networks, including the Internet, wide Area Networks, Local Area Networks, and networking protocols such as border Gateway Protocol, Open shortest Path Protocol, and Networking Networks. In this paper, we present some key graph theory concepts used to represent different types of networks. Then we describe how networks are modeled to investigate problems related to network protocols. Finally, we present some of the tools used to generate graph for representing practical networks.},
	language = {en},
	author = {Ahmat, Kamal A},
	pages = {6},
	file = {Graph Theory and Optimization Problems for Very Large Networks by Ahmat.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Theory and Optimization Problems for Very Large Networks by Ahmat.pdf:application/pdf}
}

@article{cui_citation_nodate,
	title = {Citation {Networks} as a {Multi}-layer {Graph}: {Link} {Prediction} and {Importance} {Ranking}},
	abstract = {In academia, to represent the relationships between researchers or papers, the traditional way is to analyze the citation network constructed by paper citation relationships. Our major contribution is that we incorporated multiple networks from the publication dataset, such as the paper citation network, author citation network, author collaboration network, etc. These networks can provide very useful and interesting information for analyzing the citation behavior of researchers. In this paper, we ﬁrst analyze how people are citing papers by applying logistic regression model to paper citation network. With the additional information from the author networks, we can get improved results of link prediction in citation network. Then we run a modiﬁed PageRank algorithm on paper citation network and author citation network, which can provide us with a more accurate sense of the paper and researcher impact.},
	language = {en},
	author = {Cui, Jingyu and Wang, Fan and Zhai, Jinjian},
	pages = {8},
	file = {Citation Networks as a Multi-layer Graph by Cui et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Citation Networks as a Multi-layer Graph by Cui et al.pdf:application/pdf}
}

@inproceedings{wang_survey_2015,
	title = {A {Survey} of {Graph}-{Based} {Representations} and {Techniques} for {Scientific} {Visualization}},
	doi = {10.2312/eurovisstar.20151111},
	abstract = {Graphs represent general node-link diagrams and have long been utilized in scientific visualization for data organization and management. However, using graphs as a visual representation and interface for navigating and exploring scientific data sets has a much shorter history yet the amount of work along this direction is clearly on the rise in recent years. In this paper, we take a holistic perspective and survey graph-based representations and techniques for scientific visualization. Specifically, we classify these representations and techniques into four categories, namely, partition-wise, relationship-wise, structure-wise, and provenance-wise. We survey related publications in each category, explaining the roles of graphs in related work and highlighting their similarities and differences. We also point out research trends and remaining challenges in graph-based representations and techniques for scientific visualization.},
	booktitle = {{EuroVis}},
	author = {Wang, Chaoli},
	year = {2015},
	keywords = {Graph - visual representation, Graph (discrete mathematics), Categories, Diagram, Holism, Imagery, Scientific visualization}
}

@inproceedings{xie_distributed_2014,
	title = {Distributed {Power}-law {Graph} {Computing}: {Theoretical} and {Empirical} {Analysis}},
	shorttitle = {Distributed {Power}-law {Graph} {Computing}},
	abstract = {With the emergence of big graphs in a variety of real applications like social networks, machine learning based on distributed graph-computing (DGC) frameworks has attracted much attention from big data machine learning community. In DGC frameworks, the graph partitioning (GP) strategy plays a key role to affect the performance, including the workload balance and communication cost. Typically, the degree distributions of natural graphs from real applications follow skewed power laws, which makes GP a challenging task. Recently, many methods have been proposed to solve the GP problem. However, the existing GP methods cannot achieve satisfactory performance for applications with power-law graphs. In this paper, we propose a novel vertex-cut method, called degree-based hashing (DBH), for GP. DBH makes effective use of the skewed degree distributions for GP. We theoretically prove that DBH can achieve lower communication cost than existing methods and can simultaneously guarantee good workload balance. Furthermore, empirical results on several large power-law graphs also show that DBH can outperform the state of the art.},
	booktitle = {{NIPS}},
	author = {Xie, Cong and Yan, Ling and Li, Wu-Jun and Zhang, Zhihua},
	year = {2014},
	keywords = {Big data, Emergence, Graph partition, Machine learning, Moore's law, Natural deduction, QP state machine frameworks, Social network, Vertex separator}
}

@article{ching_one_2015,
	title = {One trillion edges: graph processing at {Facebook}-scale},
	volume = {8},
	issn = {21508097},
	shorttitle = {One trillion edges},
	url = {http://dl.acm.org/citation.cfm?doid=2824032.2824077},
	doi = {10.14778/2824032.2824077},
	abstract = {Analyzing large graphs provides valuable insights for social networking and web companies in content ranking and recommendations. While numerous graph processing systems have been developed and evaluated on available benchmark graphs of up to 6.6B edges, they often face signiﬁcant difﬁculties in scaling to much larger graphs. Industry graphs can be two orders of magnitude larger - hundreds of billions or up to one trillion edges. In addition to scalability challenges, real world applications often require much more complex graph processing workﬂows than previously evaluated. In this paper, we describe the usability, performance, and scalability improvements we made to Apache Giraph, an open-source graph processing system, in order to use it on Facebook-scale graphs of up to one trillion edges. We also describe several key extensions to the original Pregel model that make it possible to develop a broader range of production graph applications and workﬂows as well as improve code reuse. Finally, we report on real-world operations as well as performance characteristics of several large-scale production applications.},
	language = {en},
	number = {12},
	urldate = {2019-08-08},
	journal = {Proceedings of the VLDB Endowment},
	author = {Ching, Avery and Edunov, Sergey and Kabiljo, Maja and Logothetis, Dionysios and Muthukrishnan, Sambavi},
	month = aug,
	year = {2015},
	pages = {1804--1815},
	file = {2015 - One trillion edges by Ching et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2015 - One trillion edges by Ching et al.pdf:application/pdf}
}

@article{mcgregor_graph_2014,
	title = {Graph stream algorithms: a survey},
	volume = {43},
	issn = {01635808},
	shorttitle = {Graph stream algorithms},
	url = {http://dl.acm.org/citation.cfm?doid=2627692.2627694},
	doi = {10.1145/2627692.2627694},
	abstract = {Over the last decade, there has been considerable interest in designing algorithms for processing massive graphs in the data stream model. The original motivation was two-fold: a) in many applications, the dynamic graphs that arise are too large to be stored in the main memory of a single machine and b) considering graph problems yields new insights into the complexity of stream computation. However, the techniques developed in this area are now ﬁnding applications in other areas including data structures for dynamic graphs, approximation algorithms, and distributed and parallel computation. We survey the state-of-the-art results; identify general techniques; and highlight some simple algorithms that illustrate basic ideas.},
	language = {en},
	number = {1},
	urldate = {2019-03-13},
	journal = {ACM SIGMOD Record},
	author = {McGregor, Andrew},
	month = may,
	year = {2014},
	pages = {9--20},
	file = {2014 - Graph stream algorithms by McGregor.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2014 - Graph stream algorithms by McGregor.pdf:application/pdf}
}

@inproceedings{kumarage_efficient_2017,
	address = {Peradeniya},
	title = {An efficient query platform for streaming and dynamic natural graphs},
	isbn = {978-1-5386-1674-1 978-1-5386-1676-5},
	url = {http://ieeexplore.ieee.org/document/8300418/},
	doi = {10.1109/ICIINFS.2017.8300418},
	abstract = {Massive scale data streaming is now prevalent and can be used to dynamically build large graphs which are then efﬁciently analyzable for insightful information. In situations where real time analytics is required approximate outcomes within time bounds may be desirable. We have identiﬁed graph summarization and TCM sketching in particular as a good technique for graph summarization for streaming data. TCM sketching provides a set of metrics such as Average Relative Error, Number of Effective Queries, Effectiveness of Effective Queries and Confusion Matrix of queries on streaming graphs. We then propose extensions to the TCM model for automatic sketch creation while the graph is being constructed and evaluate the approach with different sketch creation policies and query combinations. The proposed query framework works well with streaming graphs with 80\% to 90\% query efﬁciency and ±33 deviation from exact results.},
	language = {en},
	urldate = {2020-02-19},
	booktitle = {2017 {IEEE} {International} {Conference} on {Industrial} and {Information} {Systems} ({ICIIS})},
	publisher = {IEEE},
	author = {Kumarage, Milindu Sanoj and Horawalavithana, Yasanka and Ranasinghe, D.N.},
	month = dec,
	year = {2017},
	pages = {1--6},
	file = {2017 - An efficient query platform for streaming and dynamic natural graphs by Kumarage et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2017 - An efficient query platform for streaming and dynamic natural graphs by Kumarage et al2.pdf:application/pdf}
}

@inproceedings{kwak_what_2010,
	address = {Raleigh, North Carolina, USA},
	title = {What is {Twitter}, a social network or a news media?},
	isbn = {978-1-60558-799-8},
	url = {http://portal.acm.org/citation.cfm?doid=1772690.1772751},
	doi = {10.1145/1772690.1772751},
	abstract = {Twitter, a microblogging service less than three years old, commands more than 41 million users as of July 2009 and is growing fast. Twitter users tweet about any topic within the 140-character limit and follow others to receive their tweets. The goal of this paper is to study the topological characteristics of Twitter and its power as a new medium of information sharing.},
	language = {en},
	urldate = {2020-01-09},
	booktitle = {Proceedings of the 19th international conference on {World} wide web - {WWW} '10},
	publisher = {ACM Press},
	author = {Kwak, Haewoon and Lee, Changhyun and Park, Hosung and Moon, Sue},
	year = {2010},
	pages = {591},
	file = {2010 - What is Twitter, a social network or a news media by Kwak et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2010 - What is Twitter, a social network or a news media by Kwak et al.pdf:application/pdf}
}

@article{brin_anatomy_1998,
	title = {The anatomy of a large-scale hypertextual {Web} search engine},
	volume = {30},
	issn = {01697552},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016975529800110X},
	doi = {10.1016/S0169-7552(98)00110-X},
	abstract = {In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems.The prototype with a full text and hyperlink databaseof at least24 million pages is available at http:llgoogle.stanford.edu/ To engineer a search engine is a challenging task. Search engines index tens to hundreds of millions of Web pages involving a comparable number of distinct terms. They answer tensof millions of queriesevery day. Despite the importance of large-scalesearchengines on the Web, very little academic researchhas been done on them. Furthermore, due to rapid advance in technology and Web proliferation, creating a Web search engine today is very different from three years ago. This paper provides an in-depth description of our large-scaleWeb search engine - the first such detailed public description we know of to date. Apart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better searchresults. This paper addressesthis question of how to build a practical large-scalesystem which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want. 0 1998 Published by Elsevier Science B.V. All rights reserved.},
	language = {en},
	number = {1-7},
	urldate = {2020-01-05},
	journal = {Computer Networks and ISDN Systems},
	author = {Brin, Sergey and Page, Lawrence},
	month = apr,
	year = {1998},
	pages = {107--117},
	file = {1998 - The anatomy of a large-scale hypertextual Web search engine by Brin_Page.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/1998 - The anatomy of a large-scale hypertextual Web search engine by Brin_Page.pdf:application/pdf}
}

@article{page_pagerank_nodate,
	title = {The {PageRank} {Citation} {Ranking}: {Bringing} {Order} to the {Web}},
	url = {http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf},
	urldate = {2020-01-05},
	author = {Page, Larry},
	file = {The PageRank Citation Ranking by Page.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/The PageRank Citation Ranking by Page.pdf:application/pdf}
}

@article{liu_graph_2018,
	title = {Graph {Summarization} {Methods} and {Applications}: {A} {Survey}},
	volume = {51},
	issn = {03600300},
	shorttitle = {Graph {Summarization} {Methods} and {Applications}},
	url = {http://dl.acm.org/citation.cfm?doid=3212709.3186727},
	doi = {10.1145/3186727},
	language = {en},
	number = {3},
	urldate = {2019-03-20},
	journal = {ACM Computing Surveys},
	author = {Liu, Yike and Safavi, Tara and Dighe, Abhilash and Koutra, Danai},
	month = jun,
	year = {2018},
	pages = {1--34},
	file = {2018 - Graph Summarization Methods and Applications by Liu et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2018 - Graph Summarization Methods and Applications by Liu et al.pdf:application/pdf}
}

@article{seo_effective_2018,
	title = {An effective graph summarization and compression technique for a large-scaled graph},
	issn = {0920-8542, 1573-0484},
	url = {http://link.springer.com/10.1007/s11227-018-2245-5},
	doi = {10.1007/s11227-018-2245-5},
	language = {en},
	urldate = {2020-01-05},
	journal = {The Journal of Supercomputing},
	author = {Seo, Hojin and Park, Kisung and Han, Yongkoo and Kim, Hyunwook and Umair, Muhammad and Khan, Kifayat Ullah and Lee, Young-Koo},
	month = jan,
	year = {2018},
	file = {2018 - An effective graph summarization and compression technique for a large-scaled by Seo et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2018 - An effective graph summarization and compression technique for a large-scaled by Seo et al.pdf:application/pdf}
}

@inproceedings{dunne_motif_2013,
	address = {Paris, France},
	title = {Motif simplification: improving network visualization readability with fan, connector, and clique glyphs},
	isbn = {978-1-4503-1899-0},
	shorttitle = {Motif simplification},
	url = {http://dl.acm.org/citation.cfm?doid=2470654.2466444},
	doi = {10.1145/2470654.2466444},
	abstract = {Analyzing networks involves understanding the complex relationships between entities, as well as any attributes they may have. The widely used node-link diagrams excel at this task, but many are difﬁcult to extract meaning from because of the inherent complexity of the relationships and limited screen space. To help address this problem we introduce a technique called motif simpliﬁcation, in which common patterns of nodes and links are replaced with compact and meaningful glyphs. Well-designed glyphs have several beneﬁts: they (1) require less screen space and layout effort, (2) are easier to understand in the context of the network, (3) can reveal otherwise hidden relationships, and (4) preserve as much underlying information as possible. We tackle three frequently occurring and high-payoff motifs: fans of nodes with a single neighbor, connectors that link a set of anchor nodes, and cliques of completely connected nodes. We contribute design guidelines for motif glyphs; example glyphs for the fan, connector, and clique motifs; algorithms for detecting these motifs; a free and open source reference implementation; and results from a controlled study of 36 participants that demonstrates the effectiveness of motif simpliﬁcation.},
	language = {en},
	urldate = {2020-01-05},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '13},
	publisher = {ACM Press},
	author = {Dunne, Cody and Shneiderman, Ben},
	year = {2013},
	pages = {3247},
	file = {2013 - Motif simplification by Dunne_Shneiderman.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2013 - Motif simplification by Dunne_Shneiderman2.pdf:application/pdf}
}

@article{jin_eco_nodate,
	title = {{ECO} : {Comparative} {Visualization} of {Time}-{Evolving} {Network} {Summaries}},
	abstract = {How can we visualize, interact with, and ‘learn’ important structures of time-evolving networks? Given domain-speci c a ributes, such as node membership of functional brain regions, how can we use this domain knowledge to discover coherent structures and track their evolution over time? In this demo paper, we introduce ECO (for Evolving COmparative network visualization), a system that enables pairwise comparison of temporal graph summaries based on variations in data source and preprocessing parameters. Our system further allows the user to perform structural and temporal analysis of a graph through e cient querying and visualization of its summarizing subgraphs. ECO performs the following tasks: (a) It generates a set of temporal structures for each graph of interest using a dynamic graph summarization algorithm o ine; (b) It supports contrasting visual analysis of time-evolving network pairs by providing quantitative metrics on summary structure composition and temporal graph statistics; (c) It interactively visualizes the induced subgraph of each structure in a summary, at either a full time sequence or a time interval speci ed by the user.},
	language = {en},
	author = {Jin, Lisa and Koutra, Danai},
	pages = {8},
	file = {ECO by Jin_Koutra.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/ECO by Jin_Koutra.pdf:application/pdf}
}

@inproceedings{zhang_discovery-driven_2010,
	address = {Long Beach, CA, USA},
	title = {Discovery-driven graph summarization},
	isbn = {978-1-4244-5445-7},
	url = {http://ieeexplore.ieee.org/document/5447830/},
	doi = {10.1109/ICDE.2010.5447830},
	abstract = {Large graph datasets are ubiquitous in many domains, including social networking and biology. Graph summarization techniques are crucial in such domains as they can assist in uncovering useful insights about the patterns hidden in the underlying data. One important type of graph summarization is to produce small and informative summaries based on userselected node attributes and relationships, and allowing users to interactively drill-down or roll-up to navigate through summaries with different resolutions. However, two key components are missing from the previous work in this area that limit the use of this method in practice. First, the previous work only deals with categorical node attributes. Consequently, users have to manually bucketize numerical attributes based on domain knowledge, which is not always possible. Moreover, users often have to manually iterate through many resolutions of summaries to identify the most interesting ones. This paper addresses both these key issues to make the interactive graph summarization approach more useful in practice. We ﬁrst present a method to automatically categorize numerical attributes values by exploiting the domain knowledge hidden inside the node attributes values and graph link structures. Furthermore, we propose an interestingness measure for graph summaries to point users to the potentially most insightful summaries. Using two real datasets, we demonstrate the effectiveness and efﬁciency of our techniques.},
	language = {en},
	urldate = {2019-03-13},
	booktitle = {2010 {IEEE} 26th {International} {Conference} on {Data} {Engineering} ({ICDE} 2010)},
	publisher = {IEEE},
	author = {Zhang, Ning and Tian, Yuanyuan and Patel, Jignesh M.},
	year = {2010},
	pages = {880--891},
	file = {2010 - Discovery-driven graph summarization by Zhang et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2010 - Discovery-driven graph summarization by Zhang et al.pdf:application/pdf}
}

@inproceedings{shoaran_zero-knowledge_2013,
	address = {Silicon Valley, CA, USA},
	title = {Zero-knowledge private graph summarization},
	isbn = {978-1-4799-1293-3},
	url = {http://ieeexplore.ieee.org/document/6691628/},
	doi = {10.1109/BigData.2013.6691628},
	abstract = {Graphs have become increasingly popular for modeling data in a wide variety of applications, and graph summarization is a useful technique to analyze information from large graphs. Privacy preserving mechanisms are vital to protect the privacy of individuals or institutions when releasing aggregate numbers, such as those in graph summarization. We propose privacy-aware release of graph summarization using zero-knowledge privacy (ZKP), a recently proposed privacy framework that is more effective than differential privacy (DP) for graph and social network databases. We ﬁrst deﬁne groupbased graph summaries. Next, we present techniques to compute the parameters required to design ZKP methods for each type of aggregate data. Then, we present an approach to achieve ZKP for probabilistic graphs.},
	language = {en},
	urldate = {2020-01-05},
	booktitle = {2013 {IEEE} {International} {Conference} on {Big} {Data}},
	publisher = {IEEE},
	author = {Shoaran, Maryam and Thomo, Alex and Weber-Jahnke, Jens H.},
	month = oct,
	year = {2013},
	pages = {597--605},
	file = {2013 - Zero-knowledge private graph summarization by Shoaran et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2013 - Zero-knowledge private graph summarization by Shoaran et al.pdf:application/pdf}
}

@article{cilibrasi_clustering_2005,
	title = {Clustering by {Compression}},
	volume = {51},
	abstract = {We present a new method for clustering based on compression. The method doesn’t use subject-speciﬁc features or background knowledge, and works as follows: First, we determine a parameter-free, universal, similarity distance, the normalized compression distance or NCD , computed from the lengths of compressed data ﬁles (singly and in pairwise concatenation). Second, we apply a hierarchical clustering method. The NCD is not restricted to a speciﬁc application area, and works across application area boundaries. A theoretical precursor, the normalized information distance, co-developed by one of the authors, is provably optimal. However, the optimality comes at the price of using the non-computable notion of Kolmogorov complexity. We propose axioms to capture the real-world setting, and show that the NCD approximates optimality. To extract a hierarchy of clusters from the distance matrix, we determine a dendrogram (binary tree) by a new quartet method and a fast heuristic to implement it. The method is implemented and available as public software, and is robust under choice of different compressors. To substantiate our claims of universality and robustness, we report evidence of successful application in areas as diverse as genomics, virology, languages, literature, music, handwritten digits, astronomy, and combinations of objects from completely different domains, using statistical, dictionary, and block sorting compressors. In genomics we presented new evidence for major questions in Mammalian evolution, based on whole-mitochondrial genomic analysis: the Eutherian orders and the Marsupionta hypothesis against the Theria hypothesis.},
	language = {en},
	number = {4},
	journal = {IEEE TRANSACTIONS ON INFORMATION THEORY},
	author = {Cilibrasi, Rudi and Vitanyi, Paul M B},
	year = {2005},
	pages = {21},
	file = {2005 - Clustering by Compression by Cilibrasi_Vitanyi.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2005 - Clustering by Compression by Cilibrasi_Vitanyi.pdf:application/pdf}
}

@incollection{hutchison_compression_2006,
	address = {Berlin, Heidelberg},
	title = {Compression {Picks} {Item} {Sets} {That} {Matter}},
	volume = {4213},
	isbn = {978-3-540-45374-1 978-3-540-46048-0},
	url = {http://link.springer.com/10.1007/11871637_59},
	abstract = {Finding a comprehensive set of patterns that truly captures the characteristics of a database is a complicated matter. Frequent item set mining attempts this, but low support levels often result in exorbitant amounts of item sets. Recently we showed that by using MDL we are able to select a small number of item sets that compress the data well [11]. Here we show that this small set is a good approximation of the underlying data distribution. Using the small set in a MDL-based classifier leads to performance on par with wellknown rule-induction and association-rule based methods. Advantages are that no parameters need to be set manually and only very few item sets are used. The classification scores indicate that selecting item sets through compression is an elegant way of mining interesting patterns that can subsequently find use in many applications.},
	language = {en},
	urldate = {2020-01-05},
	booktitle = {Knowledge {Discovery} in {Databases}: {PKDD} 2006},
	publisher = {Springer Berlin Heidelberg},
	author = {van Leeuwen, Matthijs and Vreeken, Jilles and Siebes, Arno},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Fürnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
	year = {2006},
	pages = {585--592},
	file = {2006 - Compression Picks Item Sets That Matter by van Leeuwen et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2006 - Compression Picks Item Sets That Matter by van Leeuwen et al.pdf:application/pdf}
}

@article{chakrabarti_fully_nodate,
	title = {Fully {Automatic} {Cross}-associations},
	abstract = {Large, sparse binary matrices arise in numerous data mining applications, such as the analysis of market baskets, web graphs, social networks, co-citations, as well as information retrieval, collaborative ﬁltering, sparse matrix reordering, etc. Virtually all the popular methods for analysis of such matrices—e.g., k-means clustering, METIS graph partitioning, SVD/PCA and frequent itemset mining—require the user to specify various parameters, such as the number of clusters, number of principal components, number of partitions, and “support.” Choosing suitable values for such parameters is a challenging problem.},
	language = {en},
	author = {Chakrabarti, Deepayan and Modha, Dharmendra S and Papadimitriou, Spiros and Faloutsos, Christos},
	pages = {12},
	file = {Fully Automatic Cross-associations by Chakrabarti et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Fully Automatic Cross-associations by Chakrabarti et al.pdf:application/pdf}
}

@inproceedings{smets_odd_2011,
	title = {The {Odd} {One} {Out}: {Identifying} and {Characterising} {Anomalies}},
	isbn = {978-0-89871-992-5 978-1-61197-281-8},
	shorttitle = {The {Odd} {One} {Out}},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611972818.69},
	doi = {10.1137/1.9781611972818.69},
	abstract = {In many situations there exists an abundance of positive examples, but only a handful of negatives. In this paper we show how such rare cases can be identi ed and characterised in binary or transaction data.},
	language = {en},
	urldate = {2020-01-05},
	booktitle = {Proceedings of the 2011 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Smets, Koen and Vreeken, Jilles},
	month = apr,
	year = {2011},
	pages = {804--815},
	file = {2011 - The Odd One Out by Smets_Vreeken.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2011 - The Odd One Out by Smets_Vreeken.pdf:application/pdf}
}

@inproceedings{akoglu_opavion_2012,
	address = {Scottsdale, Arizona, USA},
	title = {{OPAvion}: mining and visualization in large graphs},
	isbn = {978-1-4503-1247-9},
	shorttitle = {{OPAvion}},
	url = {http://dl.acm.org/citation.cfm?doid=2213836.2213941},
	doi = {10.1145/2213836.2213941},
	abstract = {Given a large graph with millions or billions of nodes and edges, like a who-follows-whom Twitter graph, how do we scalably compute its statistics, summarize its patterns, spot anomalies, visualize and make sense of it? We present OPAvion, a graph mining system that provides a scalable, interactive workﬂow to accomplish these analysis tasks. OPAvion consists of three modules: (1) The Summarization module (Pegasus) operates oﬀ-line on massive, diskresident graphs and computes graph statistics, like PageRank scores, connected components, degree distribution, triangles, etc.; (2) The Anomaly Detection module (OddBall) uses graph statistics to mine patterns and spot anomalies, such as nodes with many contacts but few interactions with them (possibly telemarketers); (3) The Interactive Visualization module (Apolo) lets users incrementally explore the graph, starting with their chosen nodes or the ﬂagged anomalous nodes; then users can expand to the nodes’ vicinities, label them into categories, and thus interactively navigate the interesting parts of the graph.},
	language = {en},
	urldate = {2020-01-05},
	booktitle = {Proceedings of the 2012 international conference on {Management} of {Data} - {SIGMOD} '12},
	publisher = {ACM Press},
	author = {Akoglu, Leman and Chau, Duen Horng and Kang, U. and Koutra, Danai and Faloutsos, Christos},
	year = {2012},
	pages = {717},
	file = {2012 - OPAvion by Akoglu et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2012 - OPAvion by Akoglu et al.pdf:application/pdf}
}

@inproceedings{mampaey_tell_2011,
	address = {San Diego, California, USA},
	title = {Tell me what i need to know: succinctly summarizing data with itemsets},
	isbn = {978-1-4503-0813-7},
	shorttitle = {Tell me what i need to know},
	url = {http://dl.acm.org/citation.cfm?doid=2020408.2020499},
	doi = {10.1145/2020408.2020499},
	abstract = {Data analysis is an inherently iterative process. That is, what we know about the data greatly determines our expectations, and hence, what result we would ﬁnd the most interesting. With this in mind, we introduce a well-founded approach for succinctly summarizing data with a collection of itemsets; using a probabilistic maximum entropy model, we iteratively ﬁnd the most interesting itemset, and in turn update our model of the data accordingly. As we only include itemsets that are surprising with regard to the current model, the summary is guaranteed to be both descriptive and non-redundant. The algorithm that we present can either mine the top-k most interesting itemsets, or use the Bayesian Information Criterion to automatically identify the model containing only the itemsets most important for describing the data. Or, in other words, it will ‘tell you what you need to know’. Experiments on synthetic and benchmark data show that the discovered summaries are succinct, and correctly identify the key patterns in the data. The models they form attain high likelihoods, and inspection shows that they summarize the data well with increasingly speciﬁc, yet non-redundant itemsets.},
	language = {en},
	urldate = {2020-01-05},
	booktitle = {Proceedings of the 17th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '11},
	publisher = {ACM Press},
	author = {Mampaey, Michael and Tatti, Nikolaj and Vreeken, Jilles},
	year = {2011},
	pages = {573},
	file = {2011 - Tell me what i need to know by Mampaey et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2011 - Tell me what i need to know by Mampaey et al.pdf:application/pdf}
}

@inproceedings{prakash_spotting_2012,
	address = {Brussels, Belgium},
	title = {Spotting {Culprits} in {Epidemics}: {How} {Many} and {Which} {Ones}?},
	isbn = {978-1-4673-4649-8 978-0-7695-4905-7},
	shorttitle = {Spotting {Culprits} in {Epidemics}},
	url = {http://ieeexplore.ieee.org/document/6413787/},
	doi = {10.1109/ICDM.2012.136},
	abstract = {Given a snapshot of a large graph, in which an infection has been spreading for some time, can we identify those nodes from which the infection started to spread? In other words, can we reliably tell who the culprits are? In this paper we answer this question afﬁrmatively, and give an efﬁcient method called NETSLEUTH for the well-known SusceptibleInfected virus propagation model. Essentially, we are after that set of seed nodes that best explain the given snapshot. We propose to employ the Minimum Description Length principle to identify the best set of seed nodes and virus propagation ripple, as the one by which we can most succinctly describe the infected graph.},
	language = {en},
	urldate = {2020-01-05},
	booktitle = {2012 {IEEE} 12th {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Prakash, B. Aditya and Vreeken, Jilles and Faloutsos, Christos},
	month = dec,
	year = {2012},
	pages = {11--20},
	file = {2012 - Spotting Culprits in Epidemics by Prakash et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2012 - Spotting Culprits in Epidemics by Prakash et al.pdf:application/pdf}
}

@article{kivela_multilayer_2014,
	title = {Multilayer networks},
	volume = {2},
	issn = {2051-1310, 2051-1329},
	url = {https://academic.oup.com/comnet/article-lookup/doi/10.1093/comnet/cnu016},
	doi = {10.1093/comnet/cnu016},
	abstract = {Most real and engineered systems include multiple subsystems and layers of connectivity, and it is important to take such features into account to try to improve our understanding of these systems. It is thus necessary to generalize “traditional" network theory by developing (and validating) a framework and associated tools to study multilayer systems in a comprehensive fashion. The origins of such eﬀorts date back several decades and arose in multiple disciplines, and now the study of multilayer networks has become one of the most important directions in network science. In this paper, we discuss the history of multilayer networks (and related concepts) and review the exploding body of work on such networks. To unify the disparate terminology in the large body of recent work, we discuss a general framework for multilayer networks, construct a dictionary of terminology to relate the numerous existing concepts to each other, and provide a thorough discussion that compares, contrasts, and translates between related notions such as multilayer networks, multiplex networks, interdependent networks, networks of networks, and many others. We also survey and discuss existing data sets that can be represented as multilayer networks. We review attempts to generalize single-layer-network diagnostics to multilayer networks. We also discuss the rapidly expanding research on multilayer-network models and notions like community detection, connected components, tensor decompositions, and various types of dynamical processes on multilayer networks. We conclude with a summary and an outlook.},
	language = {en},
	number = {3},
	urldate = {2020-01-05},
	journal = {Journal of Complex Networks},
	author = {Kivela, M. and Arenas, A. and Barthelemy, M. and Gleeson, J. P. and Moreno, Y. and Porter, M. A.},
	month = sep,
	year = {2014},
	pages = {203--271},
	file = {2014 - Multilayer networks by Kivela et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2014 - Multilayer networks by Kivela et al.pdf:application/pdf}
}

@inproceedings{leskovec_graphs_2005,
	address = {Chicago, Illinois, USA},
	title = {Graphs over time: densification laws, shrinking diameters and possible explanations},
	isbn = {978-1-59593-135-1},
	shorttitle = {Graphs over time},
	url = {http://portal.acm.org/citation.cfm?doid=1081870.1081893},
	doi = {10.1145/1081870.1081893},
	abstract = {How do real graphs evolve over time? What are “normal” growth patterns in social, technological, and information networks? Many studies have discovered patterns in static graphs, identifying properties in a single snapshot of a large network, or in a very small number of snapshots; these include heavy tails for in- and out-degree distributions, communities, small-world phenomena, and others. However, given the lack of information about network evolution over long periods, it has been hard to convert these ﬁndings into statements about trends over time.},
	language = {en},
	urldate = {2020-01-05},
	booktitle = {Proceeding of the eleventh {ACM} {SIGKDD} international conference on {Knowledge} discovery in data mining  - {KDD} '05},
	publisher = {ACM Press},
	author = {Leskovec, Jure and Kleinberg, Jon and Faloutsos, Christos},
	year = {2005},
	pages = {177},
	file = {2005 - Graphs over time by Leskovec et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2005 - Graphs over time by Leskovec et al.pdf:application/pdf}
}

@article{cormode_improved_2003,
	title = {An {Improved} {Data} {Stream} {Summary}: {The} {Count}-{Min} {Sketch} and its {Applications}},
	abstract = {We introduce a new sublinear space data structure—the Count-Min Sketch— for summarizing data streams. Our sketch allows fundamental queries in data stream summarization such as point, range, and inner product queries to be approximately answered very quickly; in addition, it can be applied to solve several important problems in data streams such as ﬁnding quantiles, frequent items, etc. The time and space bounds we show for using the CM sketch to solve these problems signiﬁcantly improve those previously known — typically from 1/ε2 to 1/ε in factor.},
	language = {en},
	author = {Cormode, Graham and Muthukrishnan, S},
	year = {2003},
	pages = {18},
	file = {2003 - An Improved Data Stream Summary by Cormode_Muthukrishnan.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2003 - An Improved Data Stream Summary by Cormode_Muthukrishnan.pdf:application/pdf}
}

@article{zhao_gsketch:_2011,
	title = {{gSketch}: on query estimation in graph streams},
	volume = {5},
	issn = {21508097},
	shorttitle = {{gSketch}},
	url = {http://dl.acm.org/citation.cfm?doid=2078331.2078335},
	doi = {10.14778/2078331.2078335},
	abstract = {Many dynamic applications are built upon large network infrastructures, such as social networks, communication networks, biological networks and the Web. Such applications create data that can be naturally modeled as graph streams, in which edges of the underlying graph are received and updated sequentially in a form of a stream. It is often necessary and important to summarize the behavior of graph streams in order to enable eﬀective query processing. However, the sheer size and dynamic nature of graph streams present an enormous challenge to existing graph management techniques. In this paper, we propose a new graph sketch method, gSketch, which combines well studied synopses for traditional data streams with a sketch partitioning technique, to estimate and optimize the responses to basic queries on graph streams. We consider two diﬀerent scenarios for query estimation: (1) A graph stream sample is available; (2) Both a graph stream sample and a query workload sample are available. Algorithms for diﬀerent scenarios are designed respectively by partitioning a global sketch to a group of localized sketches in order to optimize the query estimation accuracy. We perform extensive experimental studies on both real and synthetic data sets and demonstrate the power and robustness of gSketch in comparison with the state-of-the-art global sketch method.},
	language = {en},
	number = {3},
	urldate = {2019-03-18},
	journal = {Proceedings of the VLDB Endowment},
	author = {Zhao, Peixiang and Aggarwal, Charu C. and Wang, Min},
	month = nov,
	year = {2011},
	pages = {193--204},
	file = {2011 - gSketch by Zhao et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2011 - gSketch by Zhao et al.pdf:application/pdf}
}

@inproceedings{tang_graph_2016,
	address = {San Francisco, California, USA},
	title = {Graph {Stream} {Summarization}: {From} {Big} {Bang} to {Big} {Crunch}},
	isbn = {978-1-4503-3531-7},
	shorttitle = {Graph {Stream} {Summarization}},
	url = {http://dl.acm.org/citation.cfm?doid=2882903.2915223},
	doi = {10.1145/2882903.2915223},
	abstract = {A graph stream, which refers to the graph with edges being updated sequentially in a form of a stream, has important applications in cyber security and social networks. Due to the sheer volume and highly dynamic nature of graph streams, the practical way of handling them is by summarization. Given a graph stream G, directed or undirected, the problem of graph stream summarization is to summarize G as S with a much smaller (sublinear) space, linear conG struction time and constant maintenance cost for each edge update, such that S allows many queries over G to be apG proximately conducted e ciently. The widely used practice of summarizing data streams is to treat each stream element independently by e.g., hash- or sample-based methods, without maintaining the connections (or relationships) between elements. Hence, existing methods can only solve ad-hoc problems, without supporting diversiﬁed and complicated analytics over graph streams. We present TCM, a novel graph stream summary. Given an incoming edge, it summarizes both node and edge information in constant time. Consequently, the summary forms a graphical sketch where edges capture the connections inside elements, and nodes maintain relationships across elements. We discuss a wide range of supported queries and establish some error bounds. In addition, we experimentally show that TCM can e↵ectively and e ciently support analytics over graph streams beyond the power of existing sketches, which demonstrates its potential to start a new line of research and applications in graph stream management.},
	language = {en},
	urldate = {2019-03-17},
	booktitle = {Proceedings of the 2016 {International} {Conference} on {Management} of {Data} - {SIGMOD} '16},
	publisher = {ACM Press},
	author = {Tang, Nan and Chen, Qing and Mitra, Prasenjit},
	year = {2016},
	pages = {1481--1496},
	file = {2016 - Graph Stream Summarization by Tang et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2016 - Graph Stream Summarization by Tang et al.pdf:application/pdf}
}

@inproceedings{khan_query-friendly_2016,
	address = {San Francisco, CA, USA},
	title = {Query-friendly compression of graph streams},
	isbn = {978-1-5090-2846-7},
	url = {http://ieeexplore.ieee.org/document/7752224/},
	doi = {10.1109/ASONAM.2016.7752224},
	abstract = {We study the problem of synopsis construction of massive graph streams arriving in real-time. Many graphs such as those formed by the activity on social networks, communication networks, and telephone networks are deﬁned dynamically as rapid edge streams on a massive domain of nodes. In these rapid and massive graph streams, it is often not possible to estimate the frequency of individual items (e.g., edges, nodes) with complete accuracy. Nevertheless, sketch-based stream summaries such as Count-Min can preserve frequency information of highfrequency items with a reasonable accuracy. However, these sketch summaries lose the underlying graph structure unless one keeps information about start and end nodes of all edges, which is prohibitively expensive. For example, the existing methods can identify the high-frequency nodes and edges, but they are unable to answer more complex structural queries such as reachability deﬁned by high-frequency edges.},
	language = {en},
	urldate = {2019-03-18},
	booktitle = {2016 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining} ({ASONAM})},
	publisher = {IEEE},
	author = {Khan, Arijit and Aggarwal, Charu},
	month = aug,
	year = {2016},
	pages = {130--137},
	file = {2016 - Query-friendly compression of graph streams by Khan_Aggarwal.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2016 - Query-friendly compression of graph streams by Khan_Aggarwal.pdf:application/pdf}
}

@article{leskovec_graph_2007,
	title = {Graph evolution: {Densification} and shrinking diameters},
	volume = {1},
	issn = {15564681},
	shorttitle = {Graph evolution},
	url = {http://portal.acm.org/citation.cfm?doid=1217299.1217301},
	doi = {10.1145/1217299.1217301},
	language = {en},
	number = {1},
	urldate = {2020-02-17},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Leskovec, Jure and Kleinberg, Jon and Faloutsos, Christos},
	month = mar,
	year = {2007},
	pages = {2--es},
	file = {2007 - Graph evolution by Leskovec et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2007 - Graph evolution by Leskovec et al.pdf:application/pdf}
}

@article{bollobas_degree_2001,
	title = {The degree sequence of a scale-free random graph process: {Degree} {Sequence} of a {Random} {Graph}},
	volume = {18},
	issn = {10429832},
	shorttitle = {The degree sequence of a scale-free random graph process},
	url = {http://doi.wiley.com/10.1002/rsa.1009},
	doi = {10.1002/rsa.1009},
	language = {en},
	number = {3},
	urldate = {2020-02-18},
	journal = {Random Structures \& Algorithms},
	author = {Bollobás, B´ela and Riordan, Oliver and Spencer, Joel and Tusnády, Gábor},
	month = may,
	year = {2001},
	pages = {279--290},
	file = {2001 - The degree sequence of a scale-free random graph process by Bollobás et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2001 - The degree sequence of a scale-free random graph process by Bollobás et al.pdf:application/pdf}
}

@article{wang_random_2006,
	title = {Random pseudofractal scale-free networks with small-world effect},
	volume = {53},
	issn = {1434-6036},
	url = {https://doi.org/10.1140/epjb/e2006-00389-0},
	doi = {10.1140/epjb/e2006-00389-0},
	abstract = {A random pseudofractal network (RPN) is generated by arecursive growing rule. The RPN is of the scale-free feature andsmall-world effect. We obtain the theoretical results of power-lawexponent γ=3, clustering coefficient C=3π2-19≈0.74, and a proof that the mean distance increases no faster thanln N, where N is the network size. These results agree withthe numerical simulation very well. In particular, we explain theproperty of growth and preferential attachment in RPNs. And theproperties of a class of general RPNs are discussed in the end.},
	language = {en},
	number = {3},
	urldate = {2020-02-18},
	journal = {The European Physical Journal B - Condensed Matter and Complex Systems},
	author = {Wang, L. and Du, F. and Dai, H. P. and Sun, Y. X.},
	month = oct,
	year = {2006},
	pages = {361--366}
}

@article{fagin_comparing_2003,
	title = {Comparing {Top} k {Lists}},
	volume = {17},
	issn = {0895-4801, 1095-7146},
	url = {http://epubs.siam.org/doi/10.1137/S0895480102412856},
	doi = {10.1137/S0895480102412856},
	abstract = {Motivated by several applications, we introduce various distance measures between “top k lists.” Some of these distance measures are metrics, while others are not. For each of these latter distance measures, we show that they are “almost” a metric in the following two seemingly unrelated aspects: (i) they satisfy a relaxed version of the polygonal (hence, triangle) inequality, and (ii) there is a metric with positive constant multiples that bound our measure above and below. This is not a coincidence—we show that these two notions of almost being a metric are same. Based on the second notion, we deﬁne two distance measures to be equivalent if they are bounded above and below by constant multiples of each other. We thereby identify a large and robust equivalence class of distance measures.},
	language = {en},
	number = {1},
	urldate = {2020-02-19},
	journal = {SIAM Journal on Discrete Mathematics},
	author = {Fagin, Ronald and Kumar, Ravi and Sivakumar, D.},
	month = jan,
	year = {2003},
	pages = {134--160},
	file = {2003 - Comparing Top k Lists by Fagin et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2003 - Comparing Top k Lists by Fagin et al.pdf:application/pdf}
}

@data{DVN/5H4TDI_2018,
	author = {Han, Xueyuan},
	publisher = {Harvard Dataverse},
	title = "{Hour-Long Wget Benign Dataset (Base Graph)}",
	year = {2018},
	version = {V1},
	doi = {10.7910/DVN/5H4TDI},
	url = {https://doi.org/10.7910/DVN/5H4TDI}
}

@misc{noauthor_snap_nodate_email,
	title = {{SNAP}: {Network} datasets: {EU} email network},
	url = {https://snap.stanford.edu/data/email-EuAll.html},
	urldate = {2020-02-18},
	file = {SNAP\: Network datasets\: EU email network:/Users/ivantha/Zotero/storage/2SE249LZ/email-EuAll.html:text/html}
}

@misc{noauthor_snap_nodate_hep,
	title = {{SNAP}: {Network} datasets: {High}-energy physics {Phenomenology} citation network},
	url = {https://snap.stanford.edu/data/cit-HepPh.html},
	urldate = {2020-02-18},
	file = {SNAP\: Network datasets\: High-energy physics Phenomenology citation network:/Users/ivantha/Zotero/storage/U26ZYQPJ/cit-HepPh.html:text/html}
}

@article{gehrke_overview_2003,
	title = {Overview of the 2003 {KDD} {Cup}},
	volume = {5},
	issn = {19310145},
	url = {http://portal.acm.org/citation.cfm?doid=980972.980992},
	doi = {10.1145/980972.980992},
	abstract = {This paper surveys the 2003 KDD Cup, a competition held in conjunction with the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) in August 2003. The competition focused on mining the complex real-life social network inherent in the e-print arXiv (arXiv.org). We describe the four KDD Cup tasks: citation prediction, download prediction, data cleaning, and an open task.},
	language = {en},
	number = {2},
	urldate = {2020-02-17},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Gehrke, Johannes and Ginsparg, Paul and Kleinberg, Jon},
	month = dec,
	year = {2003},
	pages = {149},
	file = {2003 - Overview of the 2003 KDD Cup by Gehrke et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2003 - Overview of the 2003 KDD Cup by Gehrke et al.pdf:application/pdf}
}