@inproceedings{stanton_streaming_2012,
	address = {Beijing, China},
	title = {Streaming graph partitioning for large distributed graphs},
	isbn = {978-1-4503-1462-6},
	url = {http://dl.acm.org/citation.cfm?doid=2339530.2339722},
	doi = {10.1145/2339530.2339722},
	abstract = {Extracting knowledge by performing computations on graphs is becoming increasingly challenging as graphs grow in size. A standard approach distributes the graph over a cluster of nodes, but performing computations on a distributed graph is expensive if large amount of data have to be moved. Without partitioning the graph, communication quickly becomes a limiting factor in scaling the system up. Existing graph partitioning heuristics incur high computation and communication cost on large graphs, sometimes as high as the future computation itself. Observing that the graph has to be loaded into the cluster, we ask if the partitioning can be done at the same time with a lightweight streaming algorithm.},
	language = {en},
	urldate = {2019-03-18},
	booktitle = {Proceedings of the 18th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '12},
	publisher = {ACM Press},
	author = {Stanton, Isabelle and Kliot, Gabriel},
	year = {2012},
	note = {00304},
	pages = {1222},
	file = {Stanton_Kliot_2012_Streaming graph partitioning for large distributed graphs.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Partitioning/Streaming/Stanton_Kliot_2012_Streaming graph partitioning for large distributed graphs.pdf:application/pdf}
}

@article{liu_graph_2018,
	title = {Graph {Summarization} {Methods} and {Applications}: {A} {Survey}},
	volume = {51},
	issn = {03600300},
	shorttitle = {Graph {Summarization} {Methods} and {Applications}},
	url = {http://dl.acm.org/citation.cfm?doid=3212709.3186727},
	doi = {10.1145/3186727},
	language = {en},
	number = {3},
	urldate = {2019-03-20},
	journal = {ACM Computing Surveys},
	author = {Liu, Yike and Safavi, Tara and Dighe, Abhilash and Koutra, Danai},
	month = jun,
	year = {2018},
	note = {00055},
	pages = {1--34},
	file = {Liu et al_2018_Graph Summarization Methods and Applications.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Summerization/Liu et al_2018_Graph Summarization Methods and Applications.pdf:application/pdf}
}

@article{cormode_improved_2003,
	title = {An {Improved} {Data} {Stream} {Summary}: {The} {Count}-{Min} {Sketch} and its {Applications}},
	abstract = {We introduce a new sublinear space data structure—the Count-Min Sketch— for summarizing data streams. Our sketch allows fundamental queries in data stream summarization such as point, range, and inner product queries to be approximately answered very quickly; in addition, it can be applied to solve several important problems in data streams such as ﬁnding quantiles, frequent items, etc. The time and space bounds we show for using the CM sketch to solve these problems signiﬁcantly improve those previously known — typically from 1/ε2 to 1/ε in factor.},
	language = {en},
	author = {Cormode, Graham and Muthukrishnan, S},
	year = {2003},
	note = {01215},
	pages = {18},
	file = {Cormode_Muthukrishnan_2003_An Improved Data Stream Summary.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Summerization/Cormode_Muthukrishnan_2003_An Improved Data Stream Summary.pdf:application/pdf}
}

@article{zhao_gsketch:_2011,
	title = {{gSketch}: on query estimation in graph streams},
	volume = {5},
	issn = {21508097},
	shorttitle = {{gSketch}},
	url = {http://dl.acm.org/citation.cfm?doid=2078331.2078335},
	doi = {10.14778/2078331.2078335},
	abstract = {Many dynamic applications are built upon large network infrastructures, such as social networks, communication networks, biological networks and the Web. Such applications create data that can be naturally modeled as graph streams, in which edges of the underlying graph are received and updated sequentially in a form of a stream. It is often necessary and important to summarize the behavior of graph streams in order to enable eﬀective query processing. However, the sheer size and dynamic nature of graph streams present an enormous challenge to existing graph management techniques. In this paper, we propose a new graph sketch method, gSketch, which combines well studied synopses for traditional data streams with a sketch partitioning technique, to estimate and optimize the responses to basic queries on graph streams. We consider two diﬀerent scenarios for query estimation: (1) A graph stream sample is available; (2) Both a graph stream sample and a query workload sample are available. Algorithms for diﬀerent scenarios are designed respectively by partitioning a global sketch to a group of localized sketches in order to optimize the query estimation accuracy. We perform extensive experimental studies on both real and synthetic data sets and demonstrate the power and robustness of gSketch in comparison with the state-of-the-art global sketch method.},
	language = {en},
	number = {3},
	urldate = {2019-03-18},
	journal = {Proceedings of the VLDB Endowment},
	author = {Zhao, Peixiang and Aggarwal, Charu C. and Wang, Min},
	month = nov,
	year = {2011},
	note = {00052},
	pages = {193--204},
	file = {Zhao et al_2011_gSketch.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Summerization/Streaming/Zhao et al_2011_gSketch.pdf:application/pdf}
}

@inproceedings{tang_graph_2016,
	address = {San Francisco, California, USA},
	title = {Graph {Stream} {Summarization}: {From} {Big} {Bang} to {Big} {Crunch}},
	isbn = {978-1-4503-3531-7},
	shorttitle = {Graph {Stream} {Summarization}},
	url = {http://dl.acm.org/citation.cfm?doid=2882903.2915223},
	doi = {10.1145/2882903.2915223},
	abstract = {A graph stream, which refers to the graph with edges being updated sequentially in a form of a stream, has important applications in cyber security and social networks. Due to the sheer volume and highly dynamic nature of graph streams, the practical way of handling them is by summarization. Given a graph stream G, directed or undirected, the problem of graph stream summarization is to summarize G as S with a much smaller (sublinear) space, linear conG struction time and constant maintenance cost for each edge update, such that S allows many queries over G to be apG proximately conducted e ciently. The widely used practice of summarizing data streams is to treat each stream element independently by e.g., hash- or sample-based methods, without maintaining the connections (or relationships) between elements. Hence, existing methods can only solve ad-hoc problems, without supporting diversiﬁed and complicated analytics over graph streams. We present TCM, a novel graph stream summary. Given an incoming edge, it summarizes both node and edge information in constant time. Consequently, the summary forms a graphical sketch where edges capture the connections inside elements, and nodes maintain relationships across elements. We discuss a wide range of supported queries and establish some error bounds. In addition, we experimentally show that TCM can e↵ectively and e ciently support analytics over graph streams beyond the power of existing sketches, which demonstrates its potential to start a new line of research and applications in graph stream management.},
	language = {en},
	urldate = {2019-03-17},
	booktitle = {Proceedings of the 2016 {International} {Conference} on {Management} of {Data} - {SIGMOD} '16},
	publisher = {ACM Press},
	author = {Tang, Nan and Chen, Qing and Mitra, Prasenjit},
	year = {2016},
	note = {00026},
	pages = {1481--1496},
	file = {Tang et al_2016_Graph Stream Summarization.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Summerization/Streaming/Tang et al_2016_Graph Stream Summarization.pdf:application/pdf}
}

@inproceedings{khan_query-friendly_2016,
	address = {San Francisco, CA, USA},
	title = {Query-friendly compression of graph streams},
	isbn = {978-1-5090-2846-7},
	url = {http://ieeexplore.ieee.org/document/7752224/},
	doi = {10.1109/ASONAM.2016.7752224},
	abstract = {We study the problem of synopsis construction of massive graph streams arriving in real-time. Many graphs such as those formed by the activity on social networks, communication networks, and telephone networks are deﬁned dynamically as rapid edge streams on a massive domain of nodes. In these rapid and massive graph streams, it is often not possible to estimate the frequency of individual items (e.g., edges, nodes) with complete accuracy. Nevertheless, sketch-based stream summaries such as Count-Min can preserve frequency information of highfrequency items with a reasonable accuracy. However, these sketch summaries lose the underlying graph structure unless one keeps information about start and end nodes of all edges, which is prohibitively expensive. For example, the existing methods can identify the high-frequency nodes and edges, but they are unable to answer more complex structural queries such as reachability deﬁned by high-frequency edges.},
	language = {en},
	urldate = {2019-03-18},
	booktitle = {2016 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining} ({ASONAM})},
	publisher = {IEEE},
	author = {Khan, Arijit and Aggarwal, Charu},
	month = aug,
	year = {2016},
	note = {00009},
	pages = {130--137},
	file = {Khan_Aggarwal_2016_Query-friendly compression of graph streams.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Summerization/Streaming/Khan_Aggarwal_2016_Query-friendly compression of graph streams.pdf:application/pdf}
}

@article{gou_fast_2018,
	title = {Fast and {Accurate} {Graph} {Stream} {Summarization}},
	url = {http://arxiv.org/abs/1809.01246},
	abstract = {A graph stream is a continuous sequence of data items, in which each item indicates an edge, including its two endpoints and edge weight. It forms a dynamic graph that changes with every item in the stream. Graph streams play important roles in cyber security, social networks, cloud troubleshooting systems and other fields. Due to the vast volume and high update speed of graph streams, traditional data structures for graph storage such as the adjacency matrix and the adjacency list are no longer sufficient. However, prior art of graph stream summarization, like CM sketches, gSketches, TCM and gMatrix, either supports limited kinds of queries or suffers from poor accuracy of query results. In this paper, we propose a novel Graph Stream Sketch (GSS for short) to summarize the graph streams, which has the linear space cost (O({\textbar}E{\textbar}), E is the edge set of the graph) and the constant update time complexity (O(1)) and supports all kinds of queries over graph streams with the controllable errors. Both theoretical analysis and experiment results confirm the superiority of our solution with regard to the time/space complexity and query results' precision compared with the state-of-the-art.},
	urldate = {2019-03-27},
	journal = {arXiv:1809.01246 [cs]},
	author = {Gou, Xiangyang and Zou, Lei and Zhao, Chenxingyu and Yang, Tong},
	month = sep,
	year = {2018},
	note = {00000 
arXiv: 1809.01246},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {arXiv.org Snapshot:/Users/ivantha/Zotero/storage/9PZ7G6ME/1809.html:text/html;Gou et al_2018_Fast and Accurate Graph Stream Summarization.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Summerization/Streaming/Gou et al_2018_Fast and Accurate Graph Stream Summarization.pdf:application/pdf}
}

@phdthesis{kumarage_efficient_2017,
	address = {Peradeniya},
	title = {An efficient query platform for streaming and dynamic natural graphs},
	url = {http://ieeexplore.ieee.org/document/8300418/},
	abstract = {Systems these days generate data in massive scale and processing these data to extract useful information has now become a very common practice. With the hype of Big Data, we see Big Graph is also becoming trendy where relationship between in these massive scale data are used to build massive scale graphs and then analysed for more insightful information. On the other hand, stream processing gaining lot of attention as they provides a way of extracting information in real-time. In most of the scenarios, even an approximated results are good enough if they can be generated in real-time. This research evaluates the currently available graph analysing frameworks and identiﬁes their strengths and weaknesses. Then proposes a query platform model for streaming graphs by researching and evaluating techniques and approaches which can be used for building such query platform. We identiﬁed graph summarization as a good technique for such a query platform and discovered TCM sketching as a graph summarizasion model which ﬁts our needs. Then we implemented our model using TCM sketching and evaluated the model with diﬀerent metrics like Average Relative Error, Number of Eﬀective Queries, Eﬀectiveness of Eﬀective Queries, Confusion Matrix of queries on streaming graphs. Then we evaluate the same with dynamically changing graphs and natural graphs which follows power-low degree distribution. We introduce optimisations which makes the operations of the query platform eﬃcient. Then the research propose extensions to the TCM model for automatic sketch creation while the graph is building and evaluate the success when using diﬀerent sketch creation policies. Then we evaluate the contribution of diﬀerent queries on the accuracy of the automatic sketch creation. Finally we discuss the memory usage and eﬃciency of the model. We could show the proposed model could work well with streaming graphs, even when the case of natural graphs, and produce 80\% to 90\% present eﬀective queries which had ±3 deviation from exact correct results. We could show the eﬀectiveness of the eﬀective queries are also as expected.},
	language = {en},
	urldate = {2019-03-13},
	school = {IEEE},
	author = {Kumarage, Milindu Sanoj and Horawalavithana, Yasanka and Ranasinghe, D.N.},
	month = dec,
	year = {2017},
	note = {00000},
	file = {Kumarage et al_2017_An efficient query platform for streaming and dynamic natural graphs.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/My articles/Kumarage et al_2017_An efficient query platform for streaming and dynamic natural graphs.pdf:application/pdf}
}

@article{brin_anatomy_1998,
	title = {The anatomy of a large-scale hypertextual {Web} search engine},
	volume = {30},
	issn = {01697552},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S016975529800110X},
	doi = {10.1016/S0169-7552(98)00110-X},
	abstract = {In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The prototype with a full text and hyperlink database of at least 24 million pages is available at http://google.stanford.edu/ To engineer a search engine is a challenging task. Search engines index tens to hundreds of millions of web pages involving a comparable number of distinct terms. They answer tens of millions of queries every day. Despite the importance of large-scale search engines on the web, very little academic research has been done on them. Furthermore, due to rapid advance in technology and web proliferation, creating a web search engine today is very different from three years ago. This paper provides an in-depth description of our large-scale web search engine -- the first such detailed public description we know of to date. Apart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better search results. This paper addresses this question of how to build a practical large-scale system which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want.},
	language = {en},
	number = {1-7},
	urldate = {2019-03-18},
	journal = {Computer Networks and ISDN Systems},
	author = {Brin, Sergey and Page, Lawrence},
	month = apr,
	year = {1998},
	note = {17889},
	pages = {107--117},
	file = {Brin_Page_1998_The anatomy of a large-scale hypertextual Web search engine.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graphs/Brin_Page_1998_The anatomy of a large-scale hypertextual Web search engine.pdf:application/pdf}
}

@article{ching_one_2015,
	title = {One trillion edges: graph processing at {Facebook}-scale},
	volume = {8},
	issn = {21508097},
	shorttitle = {One trillion edges},
	url = {http://dl.acm.org/citation.cfm?doid=2824032.2824077},
	doi = {10.14778/2824032.2824077},
	abstract = {Analyzing large graphs provides valuable insights for social networking and web companies in content ranking and recommendations. While numerous graph processing systems have been developed and evaluated on available benchmark graphs of up to 6.6B edges, they often face signiﬁcant difﬁculties in scaling to much larger graphs. Industry graphs can be two orders of magnitude larger - hundreds of billions or up to one trillion edges. In addition to scalability challenges, real world applications often require much more complex graph processing workﬂows than previously evaluated. In this paper, we describe the usability, performance, and scalability improvements we made to Apache Giraph, an open-source graph processing system, in order to use it on Facebook-scale graphs of up to one trillion edges. We also describe several key extensions to the original Pregel model that make it possible to develop a broader range of production graph applications and workﬂows as well as improve code reuse. Finally, we report on real-world operations as well as performance characteristics of several large-scale production applications.},
	language = {en},
	number = {12},
	urldate = {2019-08-08},
	journal = {Proceedings of the VLDB Endowment},
	author = {Ching, Avery and Edunov, Sergey and Kabiljo, Maja and Logothetis, Dionysios and Muthukrishnan, Sambavi},
	month = aug,
	year = {2015},
	pages = {1804--1815},
	file = {Ching et al_2015_One trillion edges.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graphs/Ching et al_2015_One trillion edges.pdf:application/pdf}
}

@inproceedings{garey_simplified_1974,
	address = {New York, NY, USA},
	series = {{STOC} '74},
	title = {Some {Simplified} {NP}-complete {Problems}},
	url = {http://doi.acm.org/10.1145/800119.803884},
	doi = {10.1145/800119.803884},
	abstract = {It is widely believed that showing a problem to be NP-complete is tantamount to proving its computational intractability. In this paper we show that a number of NP-complete problems remain NP-complete even when their domains are substantially restricted. First we show the completeness of SIMPLE MAX CUT (MAX CUT with edge weights restricted to value 1), and, as a corollary, the completeness of the OPTIMAL LINEAR ARRANGEMENT problem. We then show that even if the domains of the NODE COVER and DIRECTED HAMILTONIAN PATH problems are restricted to planar graphs, the two problems remain NP-complete, and that these and other graph problems remain NP-complete even when their domains are restricted to graphs with low node degrees. For GRAPH 3-COLORABILITY, NODE COVER, and UNDIRECTED HAMILTONIAN CIRCUIT, we determine essentially the lowest possible upper bounds on node degree for which the problems remain NP-complete.},
	urldate = {2019-03-18},
	booktitle = {Proceedings of the {Sixth} {Annual} {ACM} {Symposium} on {Theory} of {Computing}},
	publisher = {ACM},
	author = {Garey, M. R. and Johnson, D. S. and Stockmeyer, L.},
	year = {1974},
	note = {02845 
event-place: Seattle, Washington, USA},
	pages = {47--63},
	file = {Garey et al_1974_Some Simplified NP-complete Problems.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Partitioning/Garey et al_1974_Some Simplified NP-complete Problems.pdf:application/pdf}
}

@article{karypis_fast_1998,
	title = {A {Fast} and {High} {Quality} {Multilevel} {Scheme} for {Partitioning} {Irregular} {Graphs}},
	volume = {20},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/S1064827595287997},
	doi = {10.1137/S1064827595287997},
	abstract = {Recently, a number of researchers have investigated a class of graph partitioning algorithms that reduce the size of the graph by collapsing vertices and edges, partition the smaller graph, and then uncoarsen it to construct a partition for the original graph [Bui and Jones, Proc. of the 6th SIAM Conference on Parallel Processing for Scientiﬁc Computing, 1993, 445–452; Hendrickson and Leland, A Multilevel Algorithm for Partitioning Graphs, Tech. report SAND 93-1301, Sandia National Laboratories, Albuquerque, NM, 1993]. From the early work it was clear that multilevel techniques held great promise; however, it was not known if they can be made to consistently produce high quality partitions for graphs arising in a wide range of application domains. We investigate the eﬀectiveness of many diﬀerent choices for all three phases: coarsening, partition of the coarsest graph, and reﬁnement. In particular, we present a new coarsening heuristic (called heavy-edge heuristic) for which the size of the partition of the coarse graph is within a small factor of the size of the ﬁnal partition obtained after multilevel reﬁnement. We also present a much faster variation of the Kernighan–Lin (KL) algorithm for reﬁning during uncoarsening. We test our scheme on a large number of graphs arising in various domains including ﬁnite element methods, linear programming, VLSI, and transportation. Our experiments show that our scheme produces partitions that are consistently better than those produced by spectral partitioning schemes in substantially smaller time. Also, when our scheme is used to compute ﬁll-reducing orderings for sparse matrices, it produces orderings that have substantially smaller ﬁll than the widely used multiple minimum degree algorithm.},
	language = {en},
	number = {1},
	urldate = {2019-03-18},
	journal = {SIAM Journal on Scientific Computing},
	author = {Karypis, George and Kumar, Vipin},
	month = jan,
	year = {1998},
	note = {05093},
	pages = {359--392},
	file = {Karypis_Kumar_1998_A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Partitioning/Static/Karypis_Kumar_1998_A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs.pdf:application/pdf}
}

@techreport{hendrickson_chaco_1993,
	title = {The {Chaco} user`s guide. {Version} 1.0},
	url = {http://www.osti.gov/servlets/purl/10106339-MvWY47/native/},
	abstract = {Graph partitioning is a fundamental problem in many scienti c contexts. This document describes the capabilities and operation of Chaco 2.0, a software package designed to partition graphs. Chaco 2.0 allows for recursive application of several methods for nding small edge separators in weighted graphs. These methods include inertial, spectral, Kernighan\{\vphantom{\}}Lin and multilevel methods in addition to several simpler strategies. Each of these approaches can be used to partition the graph into two, four or eight pieces at each level of recursion. In addition, the Kernighan\{\vphantom{\}}Lin method can be used to improve partitions generated by any of the other algorithms. Brief descriptions of these methods are provided, along with references to relevant literature. Chaco 2.0 can also be used to address various graph sequencing problems, and this capability is brie y described. The user interface, input/output formats and appropriate settings for a variety of code parameters are discussed in detail, and some suggestions on algorithm selection are o ered.},
	language = {en},
	number = {SAND--93-2339, 10106339},
	urldate = {2019-03-18},
	author = {Hendrickson, B. and Leland, R.},
	month = nov,
	year = {1993},
	doi = {10.2172/10106339},
	note = {00000 },
	file = {Hendrickson_Leland_1993_The Chaco user`s guide.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Partitioning/Hendrickson_Leland_1993_The Chaco user`s guide.pdf:application/pdf}
}

@article{kim_sbv-cut:_2012,
	title = {{SBV}-{Cut}: {Vertex}-cut based graph partitioning using structural balance vertices},
	volume = {72},
	issn = {0169023X},
	shorttitle = {{SBV}-{Cut}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169023X11001480},
	doi = {10.1016/j.datak.2011.11.004},
	abstract = {Graphs are used for modeling a large spectrum of data from the web, to social connections between individuals, to concept maps and ontologies. As the number and complexities of graph based applications increase, rendering these graphs more compact, easier to understand, and navigate through are becoming crucial tasks. One approach to graph simpliﬁcation is to partition the graph into smaller parts, so that instead of the whole graph, the partitions and their inter-connections need to be considered. Common approaches to graph partitioning involve identifying sets of edges (or edge-cuts) or vertices (or vertex-cuts) whose removal partitions the graph into the target number of disconnected components. While edge-cuts result in partitions that are vertex disjoint, in vertex-cuts the data vertices can serve as bridges between the resulting data partitions; consequently, vertex-cut based approaches are especially suitable when the vertices on the vertex-cut will be replicated on all relevant partitions. A signiﬁcant challenge in vertex-cut based partitioning, however, is ensuring the balance of the resulting partitions while simultaneously minimizing the number of vertices that are cut (and thus replicated). In this paper, we propose a SBV-Cut algorithm which identiﬁes a set of balance vertices that can be used to eﬀectively and eﬃciently bisect a directed graph. The graph can then be further partitioned by a recursive application of structurally-balanced cuts to obtain a hierarchical partitioning of the graph.},
	language = {en},
	urldate = {2019-03-18},
	journal = {Data \& Knowledge Engineering},
	author = {Kim, Mijung and Candan, K. Selçuk},
	month = feb,
	year = {2012},
	note = {00061},
	pages = {285--303},
	file = {Kim_Candan_2012_SBV-Cut.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Partitioning/Static/Kim_Candan_2012_SBV-Cut.pdf:application/pdf}
}

@inproceedings{sajjad_boosting_2016,
	address = {San Francisco, CA, USA},
	title = {Boosting {Vertex}-{Cut} {Partitioning} for {Streaming} {Graphs}},
	isbn = {978-1-5090-2622-7},
	url = {http://ieeexplore.ieee.org/document/7584914/},
	doi = {10.1109/BigDataCongress.2016.10},
	abstract = {While the algorithms for streaming graph partitioning are proved promising, they fall short of creating timely partitions when applied on large graphs. For example, it takes 415 seconds for a state-of-the-art partitioner to work on a social network graph with 117 millions edges. We introduce an efﬁcient platform for boosting streaming graph partitioning algorithms. Our solution, called HoVerCut, is Horizontally and Vertically scalable. That is, it can run as a multi-threaded process on a single machine, or as a distributed partitioner across multiple machines. Our evaluations, on both real-world and synthetic graphs, show that HoVerCut speeds up the process signiﬁcantly without degrading the quality of partitioning. For example, HoVerCut partitions the aforementioned social network graph with 117 millions edges in 11 seconds that is about 37 times faster.},
	language = {en},
	urldate = {2019-03-18},
	booktitle = {2016 {IEEE} {International} {Congress} on {Big} {Data} ({BigData} {Congress})},
	publisher = {IEEE},
	author = {Sajjad, Hooman Peiro and Payberah, Amir H. and Rahimian, Fatemeh and Vlassov, Vladimir and Haridi, Seif},
	month = jun,
	year = {2016},
	note = {00015},
	pages = {1--8},
	file = {Sajjad et al_2016_Boosting Vertex-Cut Partitioning for Streaming Graphs.pdf:/Users/ivantha/Dropbox/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Partitioning/Streaming/Sajjad et al_2016_Boosting Vertex-Cut Partitioning for Streaming Graphs.pdf:application/pdf}
}