@article{brin_anatomy_1998,
	title = {The anatomy of a large-scale hypertextual Web search engine},
	volume = {30},
	issn = {01697552},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016975529800110X},
	doi = {10.1016/S0169-7552(98)00110-X},
	abstract = {In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems.The prototype with a full text and hyperlink databaseof at least24 million pages is available at http:llgoogle.stanford.edu/ To engineer a search engine is a challenging task. Search engines index tens to hundreds of millions of Web pages involving a comparable number of distinct terms. They answer tensof millions of queriesevery day. Despite the importance of large-scalesearchengines on the Web, very little academic researchhas been done on them. Furthermore, due to rapid advance in technology and Web proliferation, creating a Web search engine today is very different from three years ago. This paper provides an in-depth description of our large-{scaleWeb} search engine - the first such detailed public description we know of to date. Apart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better searchresults. This paper addressesthis question of how to build a practical large-scalesystem which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want. 0 1998 Published by Elsevier Science B.V. All rights reserved.},
	pages = {107--117},
	number = {1},
	journaltitle = {Computer Networks and {ISDN} Systems},
	shortjournal = {Computer Networks and {ISDN} Systems},
	author = {Brin, Sergey and Page, Lawrence},
	urldate = {2020-01-05},
	date = {1998-04},
	langid = {english},
	file = {1998 - The anatomy of a large-scale hypertextual Web search engine by Brin_Page.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/1998 - The anatomy of a large-scale hypertextual Web search engine by Brin_Page.pdf:application/pdf}
}

@article{page_pagerank_nodate,
	title = {The {PageRank} Citation Ranking: Bringing Order to the Web},
	url = {http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf},
	author = {Page, Larry},
	urldate = {2020-01-05},
	file = {The PageRank Citation Ranking by Page.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/The PageRank Citation Ranking by Page.pdf:application/pdf}
}

@article{ching_one_2015,
	title = {One trillion edges: graph processing at Facebook-scale},
	volume = {8},
	issn = {21508097},
	url = {http://dl.acm.org/citation.cfm?doid=2824032.2824077},
	doi = {10.14778/2824032.2824077},
	shorttitle = {One trillion edges},
	abstract = {Analyzing large graphs provides valuable insights for social networking and web companies in content ranking and recommendations. While numerous graph processing systems have been developed and evaluated on available benchmark graphs of up to 6.6B edges, they often face signiﬁcant difﬁculties in scaling to much larger graphs. Industry graphs can be two orders of magnitude larger - hundreds of billions or up to one trillion edges. In addition to scalability challenges, real world applications often require much more complex graph processing workﬂows than previously evaluated. In this paper, we describe the usability, performance, and scalability improvements we made to Apache Giraph, an open-source graph processing system, in order to use it on Facebook-scale graphs of up to one trillion edges. We also describe several key extensions to the original Pregel model that make it possible to develop a broader range of production graph applications and workﬂows as well as improve code reuse. Finally, we report on real-world operations as well as performance characteristics of several large-scale production applications.},
	pages = {1804--1815},
	number = {12},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {Proc. {VLDB} Endow.},
	author = {Ching, Avery and Edunov, Sergey and Kabiljo, Maja and Logothetis, Dionysios and Muthukrishnan, Sambavi},
	urldate = {2019-08-08},
	date = {2015-08-01},
	langid = {english},
	file = {2015 - One trillion edges by Ching et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2015 - One trillion edges by Ching et al.pdf:application/pdf}
}

@article{zhao_gsketch:_2011,
	title = {{gSketch}: on query estimation in graph streams},
	volume = {5},
	issn = {21508097},
	url = {http://dl.acm.org/citation.cfm?doid=2078331.2078335},
	doi = {10.14778/2078331.2078335},
	shorttitle = {{gSketch}},
	abstract = {Many dynamic applications are built upon large network infrastructures, such as social networks, communication networks, biological networks and the Web. Such applications create data that can be naturally modeled as graph streams, in which edges of the underlying graph are received and updated sequentially in a form of a stream. It is often necessary and important to summarize the behavior of graph streams in order to enable eﬀective query processing. However, the sheer size and dynamic nature of graph streams present an enormous challenge to existing graph management techniques. In this paper, we propose a new graph sketch method, {gSketch}, which combines well studied synopses for traditional data streams with a sketch partitioning technique, to estimate and optimize the responses to basic queries on graph streams. We consider two diﬀerent scenarios for query estimation: (1) A graph stream sample is available; (2) Both a graph stream sample and a query workload sample are available. Algorithms for diﬀerent scenarios are designed respectively by partitioning a global sketch to a group of localized sketches in order to optimize the query estimation accuracy. We perform extensive experimental studies on both real and synthetic data sets and demonstrate the power and robustness of {gSketch} in comparison with the state-of-the-art global sketch method.},
	pages = {193--204},
	number = {3},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	author = {Zhao, Peixiang and Aggarwal, Charu C. and Wang, Min},
	urldate = {2019-03-18},
	date = {2011-11-01},
	langid = {english},
	file = {2011 - gSketch by Zhao et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2011 - gSketch by Zhao et al.pdf:application/pdf}
}

@inproceedings{khan_query-friendly_2016,
	location = {San Francisco, {CA}, {USA}},
	title = {Query-friendly compression of graph streams},
	isbn = {978-1-5090-2846-7},
	url = {http://ieeexplore.ieee.org/document/7752224/},
	doi = {10.1109/ASONAM.2016.7752224},
	abstract = {We study the problem of synopsis construction of massive graph streams arriving in real-time. Many graphs such as those formed by the activity on social networks, communication networks, and telephone networks are deﬁned dynamically as rapid edge streams on a massive domain of nodes. In these rapid and massive graph streams, it is often not possible to estimate the frequency of individual items (e.g., edges, nodes) with complete accuracy. Nevertheless, sketch-based stream summaries such as Count-Min can preserve frequency information of highfrequency items with a reasonable accuracy. However, these sketch summaries lose the underlying graph structure unless one keeps information about start and end nodes of all edges, which is prohibitively expensive. For example, the existing methods can identify the high-frequency nodes and edges, but they are unable to answer more complex structural queries such as reachability deﬁned by high-frequency edges.},
	eventtitle = {2016 {IEEE}/{ACM} International Conference on Advances in Social Networks Analysis and Mining ({ASONAM})},
	pages = {130--137},
	booktitle = {2016 {IEEE}/{ACM} International Conference on Advances in Social Networks Analysis and Mining ({ASONAM})},
	publisher = {{IEEE}},
	author = {Khan, Arijit and Aggarwal, Charu},
	urldate = {2019-03-18},
	date = {2016-08},
	langid = {english},
	file = {2016 - Query-friendly compression of graph streams by Khan_Aggarwal.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2016 - Query-friendly compression of graph streams by Khan_Aggarwal.pdf:application/pdf}
}

@inproceedings{tang_graph_2016,
	location = {San Francisco, California, {USA}},
	title = {Graph Stream Summarization: From Big Bang to Big Crunch},
	isbn = {978-1-4503-3531-7},
	url = {http://dl.acm.org/citation.cfm?doid=2882903.2915223},
	doi = {10.1145/2882903.2915223},
	shorttitle = {Graph Stream Summarization},
	abstract = {A graph stream, which refers to the graph with edges being updated sequentially in a form of a stream, has important applications in cyber security and social networks. Due to the sheer volume and highly dynamic nature of graph streams, the practical way of handling them is by summarization. Given a graph stream G, directed or undirected, the problem of graph stream summarization is to summarize G as S with a much smaller (sublinear) space, linear {conG} struction time and constant maintenance cost for each edge update, such that S allows many queries over G to be {apG} proximately conducted e ciently. The widely used practice of summarizing data streams is to treat each stream element independently by e.g., hash- or sample-based methods, without maintaining the connections (or relationships) between elements. Hence, existing methods can only solve ad-hoc problems, without supporting diversiﬁed and complicated analytics over graph streams. We present {TCM}, a novel graph stream summary. Given an incoming edge, it summarizes both node and edge information in constant time. Consequently, the summary forms a graphical sketch where edges capture the connections inside elements, and nodes maintain relationships across elements. We discuss a wide range of supported queries and establish some error bounds. In addition, we experimentally show that {TCM} can e↵ectively and e ciently support analytics over graph streams beyond the power of existing sketches, which demonstrates its potential to start a new line of research and applications in graph stream management.},
	eventtitle = {the 2016 International Conference},
	pages = {1481--1496},
	booktitle = {Proceedings of the 2016 International Conference on Management of Data - {SIGMOD} '16},
	publisher = {{ACM} Press},
	author = {Tang, Nan and Chen, Qing and Mitra, Prasenjit},
	urldate = {2019-03-17},
	date = {2016},
	langid = {english},
	file = {2016 - Graph Stream Summarization by Tang et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2016 - Graph Stream Summarization by Tang et al.pdf:application/pdf}
}

@article{cormode_improved_2003,
	title = {An Improved Data Stream Summary: The Count-Min Sketch and its Applications},
	abstract = {We introduce a new sublinear space data structure—the Count-Min Sketch— for summarizing data streams. Our sketch allows fundamental queries in data stream summarization such as point, range, and inner product queries to be approximately answered very quickly; in addition, it can be applied to solve several important problems in data streams such as ﬁnding quantiles, frequent items, etc. The time and space bounds we show for using the {CM} sketch to solve these problems signiﬁcantly improve those previously known — typically from 1/ε2 to 1/ε in factor.},
	pages = {18},
	author = {Cormode, Graham and Muthukrishnan, S},
	date = {2003},
	langid = {english},
	file = {2003 - An Improved Data Stream Summary by Cormode_Muthukrishnan.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2003 - An Improved Data Stream Summary by Cormode_Muthukrishnan.pdf:application/pdf}
}

@inproceedings{roy_augmented_2016,
	location = {San Francisco, California, {USA}},
	title = {Augmented Sketch: Faster and More Accurate Stream Processing},
	isbn = {978-1-4503-3531-7},
	url = {http://dl.acm.org/citation.cfm?doid=2882903.2882948},
	doi = {10.1145/2882903.2882948},
	shorttitle = {Augmented Sketch},
	abstract = {Approximated algorithms are often used to estimate the frequency of items on high volume, fast data streams. The most common ones are variations of Count-Min sketch, which use sub-linear space for the count, but can produce errors in the counts of the most frequent items and can misclassify low-frequency items. In this paper, we improve the accuracy of sketch-based algorithms by increasing the frequency estimation accuracy of the most frequent items and reducing the possible misclassiﬁcation of low-frequency items, while also improving the overall throughput.},
	eventtitle = {the 2016 International Conference},
	pages = {1449--1463},
	booktitle = {Proceedings of the 2016 International Conference on Management of Data - {SIGMOD} '16},
	publisher = {{ACM} Press},
	author = {Roy, Pratanu and Khan, Arijit and Alonso, Gustavo},
	urldate = {2019-04-22},
	date = {2016},
	langid = {english},
	file = {2016 - Augmented Sketch by Roy et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2016 - Augmented Sketch by Roy et al.pdf:application/pdf}
}

@article{gou_fast_2018,
	title = {Fast and Accurate Graph Stream Summarization},
	url = {http://arxiv.org/abs/1809.01246},
	abstract = {A graph stream is a continuous sequence of data items, in which each item indicates an edge, including its two endpoints and edge weight. It forms a dynamic graph that changes with every item in the stream. Graph streams play important roles in cyber security, social networks, cloud troubleshooting systems and other fields. Due to the vast volume and high update speed of graph streams, traditional data structures for graph storage such as the adjacency matrix and the adjacency list are no longer sufficient. However, prior art of graph stream summarization, like {CM} sketches, {gSketches}, {TCM} and {gMatrix}, either supports limited kinds of queries or suffers from poor accuracy of query results. In this paper, we propose a novel Graph Stream Sketch ({GSS} for short) to summarize the graph streams, which has the linear space cost (O({\textbar}E{\textbar}), E is the edge set of the graph) and the constant update time complexity (O(1)) and supports all kinds of queries over graph streams with the controllable errors. Both theoretical analysis and experiment results confirm the superiority of our solution with regard to the time/space complexity and query results' precision compared with the state-of-the-art.},
	journaltitle = {{arXiv}:1809.01246 [cs]},
	author = {Gou, Xiangyang and Zou, Lei and Zhao, Chenxingyu and Yang, Tong},
	urldate = {2019-03-27},
	date = {2018-09-04},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {2018 - Fast and Accurate Graph Stream Summarization by Gou et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2018 - Fast and Accurate Graph Stream Summarization by Gou et al.pdf:application/pdf;arXiv.org Snapshot:/Users/ivantha/Zotero/storage/9PZ7G6ME/1809.html:text/html}
}

@inproceedings{mishra_modelling_2014,
	title = {Modelling of Social Network using Graph Theoretical Approach},
	abstract = {This paper describes the model of formation and properties of social network via a graph theoretical approach. The paper considers the interaction between different sets of people in a social network. It also describes the additional information about each individual in a network. We have also described the matrix representation of social network. The purpose of this paper is to review the graphical model of social networking. This paper is about how two persons are related to each other and how they can access each other‟s resources. A social network is a social structure made up of individuals (or organizations) called "nodes", which are tied(connected) by one or more specific types of interdependency, such as friendship, kinship, common interest, financial exchange, dislike, sexual relationships, or relationships of beliefs, knowledge or prestige.},
	author = {Mishra, Sweata and Borboruah, Rupam and Choudhury, Bharadwaj and Rakshit, Sandip},
	date = {2014},
	keywords = {Graph - visual representation, Social network, Graph theory, Graphical model, Interdependence, List of Code Lyoko episodes, Matrix representation, Social structure, The Matrix}
}

@article{ahmat_graph_nodate,
	title = {Graph Theory and Optimization Problems for Very Large Networks},
	abstract = {Graph theory provides a primary tool for analyzing and designing computer communication networks. In the past few decades, Graph theory has been used to study various types of networks, including the Internet, wide Area Networks, Local Area Networks, and networking protocols such as border Gateway Protocol, Open shortest Path Protocol, and Networking Networks. In this paper, we present some key graph theory concepts used to represent different types of networks. Then we describe how networks are modeled to investigate problems related to network protocols. Finally, we present some of the tools used to generate graph for representing practical networks.},
	pages = {6},
	author = {Ahmat, Kamal A},
	langid = {english},
	file = {Graph Theory and Optimization Problems for Very Large Networks by Ahmat.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Theory and Optimization Problems for Very Large Networks by Ahmat.pdf:application/pdf}
}

@article{cui_citation_nodate,
	title = {Citation Networks as a Multi-layer Graph: Link Prediction and Importance Ranking},
	abstract = {In academia, to represent the relationships between researchers or papers, the traditional way is to analyze the citation network constructed by paper citation relationships. Our major contribution is that we incorporated multiple networks from the publication dataset, such as the paper citation network, author citation network, author collaboration network, etc. These networks can provide very useful and interesting information for analyzing the citation behavior of researchers. In this paper, we ﬁrst analyze how people are citing papers by applying logistic regression model to paper citation network. With the additional information from the author networks, we can get improved results of link prediction in citation network. Then we run a modiﬁed {PageRank} algorithm on paper citation network and author citation network, which can provide us with a more accurate sense of the paper and researcher impact.},
	pages = {8},
	author = {Cui, Jingyu and Wang, Fan and Zhai, Jinjian},
	langid = {english},
	file = {Citation Networks as a Multi-layer Graph by Cui et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Citation Networks as a Multi-layer Graph by Cui et al.pdf:application/pdf}
}

@inproceedings{wang_survey_2015,
	title = {A Survey of Graph-Based Representations and Techniques for Scientific Visualization},
	doi = {10.2312/eurovisstar.20151111},
	abstract = {Graphs represent general node-link diagrams and have long been utilized in scientific visualization for data organization and management. However, using graphs as a visual representation and interface for navigating and exploring scientific data sets has a much shorter history yet the amount of work along this direction is clearly on the rise in recent years. In this paper, we take a holistic perspective and survey graph-based representations and techniques for scientific visualization. Specifically, we classify these representations and techniques into four categories, namely, partition-wise, relationship-wise, structure-wise, and provenance-wise. We survey related publications in each category, explaining the roles of graphs in related work and highlighting their similarities and differences. We also point out research trends and remaining challenges in graph-based representations and techniques for scientific visualization.},
	booktitle = {{EuroVis}},
	author = {Wang, Chaoli},
	date = {2015},
	keywords = {Graph - visual representation, Graph (discrete mathematics), Categories, Diagram, Holism, Imagery, Scientific visualization}
}

@inproceedings{xie_distributed_2014,
	title = {Distributed Power-law Graph Computing: Theoretical and Empirical Analysis},
	shorttitle = {Distributed Power-law Graph Computing},
	abstract = {With the emergence of big graphs in a variety of real applications like social networks, machine learning based on distributed graph-computing ({DGC}) frameworks has attracted much attention from big data machine learning community. In {DGC} frameworks, the graph partitioning ({GP}) strategy plays a key role to affect the performance, including the workload balance and communication cost. Typically, the degree distributions of natural graphs from real applications follow skewed power laws, which makes {GP} a challenging task. Recently, many methods have been proposed to solve the {GP} problem. However, the existing {GP} methods cannot achieve satisfactory performance for applications with power-law graphs. In this paper, we propose a novel vertex-cut method, called degree-based hashing ({DBH}), for {GP}. {DBH} makes effective use of the skewed degree distributions for {GP}. We theoretically prove that {DBH} can achieve lower communication cost than existing methods and can simultaneously guarantee good workload balance. Furthermore, empirical results on several large power-law graphs also show that {DBH} can outperform the state of the art.},
	booktitle = {{NIPS}},
	author = {Xie, Cong and Yan, Ling and Li, Wu-Jun and Zhang, Zhihua},
	date = {2014},
	keywords = {Big data, Machine learning, Emergence, Graph partition, Moore's law, Natural deduction, {QP} state machine frameworks, Social network, Vertex separator}
}

@inproceedings{kwak_what_2010,
	location = {Raleigh, North Carolina, {USA}},
	title = {What is Twitter, a social network or a news media?},
	isbn = {978-1-60558-799-8},
	url = {http://portal.acm.org/citation.cfm?doid=1772690.1772751},
	doi = {10.1145/1772690.1772751},
	abstract = {Twitter, a microblogging service less than three years old, commands more than 41 million users as of July 2009 and is growing fast. Twitter users tweet about any topic within the 140-character limit and follow others to receive their tweets. The goal of this paper is to study the topological characteristics of Twitter and its power as a new medium of information sharing.},
	eventtitle = {the 19th international conference},
	pages = {591},
	booktitle = {Proceedings of the 19th international conference on World wide web - {WWW} '10},
	publisher = {{ACM} Press},
	author = {Kwak, Haewoon and Lee, Changhyun and Park, Hosung and Moon, Sue},
	urldate = {2020-01-09},
	date = {2010},
	langid = {english},
	file = {2010 - What is Twitter, a social network or a news media by Kwak et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2010 - What is Twitter, a social network or a news media by Kwak et al.pdf:application/pdf}
}

@article{mcgregor_graph_2014,
	title = {Graph stream algorithms: a survey},
	volume = {43},
	issn = {01635808},
	url = {http://dl.acm.org/citation.cfm?doid=2627692.2627694},
	doi = {10.1145/2627692.2627694},
	shorttitle = {Graph stream algorithms},
	abstract = {Over the last decade, there has been considerable interest in designing algorithms for processing massive graphs in the data stream model. The original motivation was two-fold: a) in many applications, the dynamic graphs that arise are too large to be stored in the main memory of a single machine and b) considering graph problems yields new insights into the complexity of stream computation. However, the techniques developed in this area are now ﬁnding applications in other areas including data structures for dynamic graphs, approximation algorithms, and distributed and parallel computation. We survey the state-of-the-art results; identify general techniques; and highlight some simple algorithms that illustrate basic ideas.},
	pages = {9--20},
	number = {1},
	journaltitle = {{ACM} {SIGMOD} Record},
	author = {{McGregor}, Andrew},
	urldate = {2019-03-13},
	date = {2014-05-13},
	langid = {english},
	file = {2014 - Graph stream algorithms by McGregor.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2014 - Graph stream algorithms by McGregor.pdf:application/pdf}
}

@online{noauthor_simplified_nodate,
	title = {Some simplified {NP}-complete problems {\textbar} Proceedings of the sixth annual {ACM} symposium on Theory of computing},
	url = {https://dl.acm.org/doi/abs/10.1145/800119.803884},
	urldate = {2020-01-04},
	file = {Snapshot:/Users/ivantha/Zotero/storage/6JSKGIVT/800119.html:text/html;Some simplified NP-complete problems Proceedings of the sixth annual ACM by.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Some simplified NP-complete problems Proceedings of the sixth annual ACM by.pdf:application/pdf}
}

@inproceedings{stanton_streaming_2012,
	location = {Beijing, China},
	title = {Streaming graph partitioning for large distributed graphs},
	isbn = {978-1-4503-1462-6},
	url = {http://dl.acm.org/citation.cfm?doid=2339530.2339722},
	doi = {10.1145/2339530.2339722},
	abstract = {Extracting knowledge by performing computations on graphs is becoming increasingly challenging as graphs grow in size. A standard approach distributes the graph over a cluster of nodes, but performing computations on a distributed graph is expensive if large amount of data have to be moved. Without partitioning the graph, communication quickly becomes a limiting factor in scaling the system up. Existing graph partitioning heuristics incur high computation and communication cost on large graphs, sometimes as high as the future computation itself. Observing that the graph has to be loaded into the cluster, we ask if the partitioning can be done at the same time with a lightweight streaming algorithm.},
	eventtitle = {the 18th {ACM} {SIGKDD} international conference},
	pages = {1222},
	booktitle = {Proceedings of the 18th {ACM} {SIGKDD} international conference on Knowledge discovery and data mining - {KDD} '12},
	publisher = {{ACM} Press},
	author = {Stanton, Isabelle and Kliot, Gabriel},
	urldate = {2019-03-18},
	date = {2012},
	langid = {english},
	file = {2012 - Streaming graph partitioning for large distributed graphs by Stanton_Kliot.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2012 - Streaming graph partitioning for large distributed graphs by Stanton_Kliot.pdf:application/pdf}
}

@article{karypis_fast_1998,
	title = {A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs},
	volume = {20},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/S1064827595287997},
	doi = {10.1137/S1064827595287997},
	abstract = {Recently, a number of researchers have investigated a class of graph partitioning algorithms that reduce the size of the graph by collapsing vertices and edges, partition the smaller graph, and then uncoarsen it to construct a partition for the original graph [Bui and Jones, Proc. of the 6th {SIAM} Conference on Parallel Processing for Scientiﬁc Computing, 1993, 445–452; Hendrickson and Leland, A Multilevel Algorithm for Partitioning Graphs, Tech. report {SAND} 93-1301, Sandia National Laboratories, Albuquerque, {NM}, 1993]. From the early work it was clear that multilevel techniques held great promise; however, it was not known if they can be made to consistently produce high quality partitions for graphs arising in a wide range of application domains. We investigate the eﬀectiveness of many diﬀerent choices for all three phases: coarsening, partition of the coarsest graph, and reﬁnement. In particular, we present a new coarsening heuristic (called heavy-edge heuristic) for which the size of the partition of the coarse graph is within a small factor of the size of the ﬁnal partition obtained after multilevel reﬁnement. We also present a much faster variation of the Kernighan–Lin ({KL}) algorithm for reﬁning during uncoarsening. We test our scheme on a large number of graphs arising in various domains including ﬁnite element methods, linear programming, {VLSI}, and transportation. Our experiments show that our scheme produces partitions that are consistently better than those produced by spectral partitioning schemes in substantially smaller time. Also, when our scheme is used to compute ﬁll-reducing orderings for sparse matrices, it produces orderings that have substantially smaller ﬁll than the widely used multiple minimum degree algorithm.},
	pages = {359--392},
	number = {1},
	journaltitle = {{SIAM} Journal on Scientific Computing},
	shortjournal = {{SIAM} J. Sci. Comput.},
	author = {Karypis, George and Kumar, Vipin},
	urldate = {2020-01-04},
	date = {1998-01},
	langid = {english},
	file = {1998 - A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs by Karypis_Kumar.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/1998 - A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs by Karypis_Kumar.pdf:application/pdf}
}

@report{hendrickson_chaco_1993,
	title = {The Chaco user`s guide. Version 1.0},
	url = {http://www.osti.gov/servlets/purl/10106339-MvWY47/native/},
	pages = {SAND--93--2339, 10106339},
	number = {{SAND}--93-2339, 10106339},
	author = {Hendrickson, B. and Leland, R.},
	urldate = {2020-01-04},
	date = {1993-11-01},
	langid = {english},
	file = {1993 - The Chaco user`s guide by Hendrickson_Leland.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/1993 - The Chaco user`s guide by Hendrickson_Leland.pdf:application/pdf}
}

@article{kim_sbv-cut:_2012,
	title = {{SBV}-Cut: Vertex-cut based graph partitioning using structural balance vertices},
	volume = {72},
	issn = {0169023X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169023X11001480},
	doi = {10.1016/j.datak.2011.11.004},
	shorttitle = {{SBV}-Cut},
	abstract = {Graphs are used for modeling a large spectrum of data from the web, to social connections between individuals, to concept maps and ontologies. As the number and complexities of graph based applications increase, rendering these graphs more compact, easier to understand, and navigate through are becoming crucial tasks. One approach to graph simpliﬁcation is to partition the graph into smaller parts, so that instead of the whole graph, the partitions and their inter-connections need to be considered. Common approaches to graph partitioning involve identifying sets of edges (or edge-cuts) or vertices (or vertex-cuts) whose removal partitions the graph into the target number of disconnected components. While edge-cuts result in partitions that are vertex disjoint, in vertex-cuts the data vertices can serve as bridges between the resulting data partitions; consequently, vertex-cut based approaches are especially suitable when the vertices on the vertex-cut will be replicated on all relevant partitions. A signiﬁcant challenge in vertex-cut based partitioning, however, is ensuring the balance of the resulting partitions while simultaneously minimizing the number of vertices that are cut (and thus replicated). In this paper, we propose a {SBV}-Cut algorithm which identiﬁes a set of balance vertices that can be used to eﬀectively and eﬃciently bisect a directed graph. The graph can then be further partitioned by a recursive application of structurally-balanced cuts to obtain a hierarchical partitioning of the graph.},
	pages = {285--303},
	journaltitle = {Data \& Knowledge Engineering},
	author = {Kim, Mijung and Candan, K. Selçuk},
	urldate = {2019-03-18},
	date = {2012-02},
	langid = {english},
	file = {2012 - SBV-Cut by Kim_Candan.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2012 - SBV-Cut by Kim_Candan.pdf:application/pdf}
}

@inproceedings{sajjad_boosting_2016,
	location = {San Francisco, {CA}, {USA}},
	title = {Boosting Vertex-Cut Partitioning for Streaming Graphs},
	isbn = {978-1-5090-2622-7},
	url = {http://ieeexplore.ieee.org/document/7584914/},
	doi = {10.1109/BigDataCongress.2016.10},
	abstract = {While the algorithms for streaming graph partitioning are proved promising, they fall short of creating timely partitions when applied on large graphs. For example, it takes 415 seconds for a state-of-the-art partitioner to work on a social network graph with 117 millions edges. We introduce an efﬁcient platform for boosting streaming graph partitioning algorithms. Our solution, called {HoVerCut}, is Horizontally and Vertically scalable. That is, it can run as a multi-threaded process on a single machine, or as a distributed partitioner across multiple machines. Our evaluations, on both real-world and synthetic graphs, show that {HoVerCut} speeds up the process signiﬁcantly without degrading the quality of partitioning. For example, {HoVerCut} partitions the aforementioned social network graph with 117 millions edges in 11 seconds that is about 37 times faster.},
	eventtitle = {2016 {IEEE} International Congress on Big Data ({BigData} Congress)},
	pages = {1--8},
	booktitle = {2016 {IEEE} International Congress on Big Data ({BigData} Congress)},
	publisher = {{IEEE}},
	author = {Sajjad, Hooman Peiro and Payberah, Amir H. and Rahimian, Fatemeh and Vlassov, Vladimir and Haridi, Seif},
	urldate = {2019-03-18},
	date = {2016-06},
	langid = {english},
	file = {2016 - Boosting Vertex-Cut Partitioning for Streaming Graphs by Sajjad et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2016 - Boosting Vertex-Cut Partitioning for Streaming Graphs by Sajjad et al.pdf:application/pdf}
}

@article{xie_s-powergraph_nodate,
	title = {S-{PowerGraph}: Streaming Graph Partitioning for Natural Graphs by Vertex-Cut},
	abstract = {One standard solution for analyzing large natural graphs is to adopt distributed computation on clusters. In distributed computation, graph partitioning ({GP}) methods assign the vertices or edges of a graph to diﬀerent machines in a balanced way so that some distributed algorithms can be adapted for. Most of traditional {GP} methods are ofﬂine, which means that the whole graph has been observed before partitioning. However, the oﬄine methods often incur high computation cost. Hence, streaming graph partitioning ({SGP}) methods, which can partition graphs in an online way, have recently attracted great attention in distributed computation. There exist two typical {GP} strategies: edge-cut and vertex-cut. Most {SGP} methods adopt edge-cut, but few vertex-cut methods have been proposed for {SGP}. However, the vertex-cut strategy would be a better choice than the edge-cut strategy because the degree of a natural graph in general follows a highly skewed power-law distribution. Thus, we propose a novel method, called {SPowerGraph}, for {SGP} of natural graphs by vertex-cut. Our S-{PowerGraph} method is simple but eﬀective. Experiments on several large natural graphs and synthetic graphs show that our S-{PowerGraph} can outperform the state-of-the-art baselines.},
	pages = {11},
	author = {Xie, Cong and Li, Wu-Jun and Zhang, Zhihua},
	langid = {english},
	file = {S-PowerGraph by Xie et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/S-PowerGraph by Xie et al.pdf:application/pdf}
}

@article{gonzalez_powergraph_nodate,
	title = {{PowerGraph}: Distributed Graph-Parallel Computation on Natural Graphs},
	abstract = {Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and {GraphLab}. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability.},
	pages = {14},
	author = {Gonzalez, Joseph E and Low, Yucheng and Gu, Haijie},
	langid = {english},
	file = {PowerGraph by Gonzalez et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/PowerGraph by Gonzalez et al.pdf:application/pdf}
}

@article{liu_graph_2018,
	title = {Graph Summarization Methods and Applications: A Survey},
	volume = {51},
	issn = {03600300},
	url = {http://dl.acm.org/citation.cfm?doid=3212709.3186727},
	doi = {10.1145/3186727},
	shorttitle = {Graph Summarization Methods and Applications},
	pages = {1--34},
	number = {3},
	journaltitle = {{ACM} Computing Surveys},
	author = {Liu, Yike and Safavi, Tara and Dighe, Abhilash and Koutra, Danai},
	urldate = {2019-03-20},
	date = {2018-06-22},
	langid = {english},
	file = {2018 - Graph Summarization Methods and Applications by Liu et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2018 - Graph Summarization Methods and Applications by Liu et al.pdf:application/pdf}
}

@article{riondato_graph_nodate,
	title = {Graph Summarization with Quality Guarantees},
	abstract = {We study the problem of graph summarization. Given a large graph we aim at producing a concise lossy representation (a summary) that can be stored in main memory and used to approximately answer queries about the original graph much faster than by using the exact representation.},
	pages = {33},
	author = {Riondato, Matteo and Garcıa-Soriano, David and Bonchi, Francesco},
	langid = {english},
	file = {Graph Summarization with Quality Guarantees by Riondato et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Graph Summarization with Quality Guarantees by Riondato et al.pdf:application/pdf}
}

@inproceedings{dunne_motif_2013,
	location = {Paris, France},
	title = {Motif simplification: improving network visualization readability with fan, connector, and clique glyphs},
	isbn = {978-1-4503-1899-0},
	url = {http://dl.acm.org/citation.cfm?doid=2470654.2466444},
	doi = {10.1145/2470654.2466444},
	shorttitle = {Motif simplification},
	abstract = {Analyzing networks involves understanding the complex relationships between entities, as well as any attributes they may have. The widely used node-link diagrams excel at this task, but many are difﬁcult to extract meaning from because of the inherent complexity of the relationships and limited screen space. To help address this problem we introduce a technique called motif simpliﬁcation, in which common patterns of nodes and links are replaced with compact and meaningful glyphs. Well-designed glyphs have several beneﬁts: they (1) require less screen space and layout effort, (2) are easier to understand in the context of the network, (3) can reveal otherwise hidden relationships, and (4) preserve as much underlying information as possible. We tackle three frequently occurring and high-payoff motifs: fans of nodes with a single neighbor, connectors that link a set of anchor nodes, and cliques of completely connected nodes. We contribute design guidelines for motif glyphs; example glyphs for the fan, connector, and clique motifs; algorithms for detecting these motifs; a free and open source reference implementation; and results from a controlled study of 36 participants that demonstrates the effectiveness of motif simpliﬁcation.},
	eventtitle = {the {SIGCHI} Conference},
	pages = {3247},
	booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems - {CHI} '13},
	publisher = {{ACM} Press},
	author = {Dunne, Cody and Shneiderman, Ben},
	urldate = {2020-01-05},
	date = {2013},
	langid = {english},
	file = {2013 - Motif simplification by Dunne_Shneiderman.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2013 - Motif simplification by Dunne_Shneiderman2.pdf:application/pdf}
}

@article{jin_eco_nodate,
	title = {{ECO} : Comparative Visualization of Time-Evolving Network Summaries},
	abstract = {How can we visualize, interact with, and ‘learn’ important structures of time-evolving networks? Given domain-speci c a ributes, such as node membership of functional brain regions, how can we use this domain knowledge to discover coherent structures and track their evolution over time? In this demo paper, we introduce {ECO} (for Evolving {COmparative} network visualization), a system that enables pairwise comparison of temporal graph summaries based on variations in data source and preprocessing parameters. Our system further allows the user to perform structural and temporal analysis of a graph through e cient querying and visualization of its summarizing subgraphs. {ECO} performs the following tasks: (a) It generates a set of temporal structures for each graph of interest using a dynamic graph summarization algorithm o ine; (b) It supports contrasting visual analysis of time-evolving network pairs by providing quantitative metrics on summary structure composition and temporal graph statistics; (c) It interactively visualizes the induced subgraph of each structure in a summary, at either a full time sequence or a time interval speci ed by the user.},
	pages = {8},
	author = {Jin, Lisa and Koutra, Danai},
	langid = {english},
	file = {ECO by Jin_Koutra.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/ECO by Jin_Koutra.pdf:application/pdf}
}

@article{seo_effective_2018,
	title = {An effective graph summarization and compression technique for a large-scaled graph},
	issn = {0920-8542, 1573-0484},
	url = {http://link.springer.com/10.1007/s11227-018-2245-5},
	doi = {10.1007/s11227-018-2245-5},
	journaltitle = {The Journal of Supercomputing},
	shortjournal = {J Supercomput},
	author = {Seo, Hojin and Park, Kisung and Han, Yongkoo and Kim, Hyunwook and Umair, Muhammad and Khan, Kifayat Ullah and Lee, Young-Koo},
	urldate = {2020-01-05},
	date = {2018-01-15},
	langid = {english},
	file = {2018 - An effective graph summarization and compression technique for a large-scaled by Seo et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2018 - An effective graph summarization and compression technique for a large-scaled by Seo et al.pdf:application/pdf}
}

@inproceedings{schulz_grooming_2013,
	title = {Grooming the hairball - how to tidy up network visualizations?},
	abstract = {Every visualization researcher and practitioner knows the painful experience of a beautifully designed network layout breaking down once the input graph scales up to realistic node and edge counts. The resulting "hairball" suffers from cluttering and overplotting to an extreme that renders it unusable for any practical purposes. Since researchers have had this experience for decades, various approaches have been developed on all stages of the visualization pipeline to alleviate this problem. They range from filtering and clustering techniques on the data level to modern {GPU}-based techniques on the image level. This tutorial gives an overview of these techniques and discusses their applicability and interplay in different application scenarios. By doing so, it provides a unique problem-oriented perspective on the field of scalable network visualization, which is an area of active research today more than ever. The tutorial serves mainly to further the understanding of network visualization beyond the point of creating an initial layout. It thus caters to an intermediate level audience with some basic knowledge on graph layout and visualization, but it will certainly present an interesting cross-section through the larger domains of network visualization and graph drawing for established researchers as well.},
	author = {Schulz, Hans-Jörg and Hurter, Christophe},
	date = {2013},
	keywords = {Cluster analysis, Graph drawing, Graphics processing unit, {HTML} Tidy, Rendering (computer graphics), Scalability, Usability}
}

@inproceedings{zhang_discovery-driven_2010,
	location = {Long Beach, {CA}, {USA}},
	title = {Discovery-driven graph summarization},
	isbn = {978-1-4244-5445-7},
	url = {http://ieeexplore.ieee.org/document/5447830/},
	doi = {10.1109/ICDE.2010.5447830},
	abstract = {Large graph datasets are ubiquitous in many domains, including social networking and biology. Graph summarization techniques are crucial in such domains as they can assist in uncovering useful insights about the patterns hidden in the underlying data. One important type of graph summarization is to produce small and informative summaries based on userselected node attributes and relationships, and allowing users to interactively drill-down or roll-up to navigate through summaries with different resolutions. However, two key components are missing from the previous work in this area that limit the use of this method in practice. First, the previous work only deals with categorical node attributes. Consequently, users have to manually bucketize numerical attributes based on domain knowledge, which is not always possible. Moreover, users often have to manually iterate through many resolutions of summaries to identify the most interesting ones. This paper addresses both these key issues to make the interactive graph summarization approach more useful in practice. We ﬁrst present a method to automatically categorize numerical attributes values by exploiting the domain knowledge hidden inside the node attributes values and graph link structures. Furthermore, we propose an interestingness measure for graph summaries to point users to the potentially most insightful summaries. Using two real datasets, we demonstrate the effectiveness and efﬁciency of our techniques.},
	eventtitle = {2010 {IEEE} 26th International Conference on Data Engineering ({ICDE} 2010)},
	pages = {880--891},
	booktitle = {2010 {IEEE} 26th International Conference on Data Engineering ({ICDE} 2010)},
	publisher = {{IEEE}},
	author = {Zhang, Ning and Tian, Yuanyuan and Patel, Jignesh M.},
	urldate = {2019-03-13},
	date = {2010},
	langid = {english},
	file = {2010 - Discovery-driven graph summarization by Zhang et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2010 - Discovery-driven graph summarization by Zhang et al.pdf:application/pdf}
}

@inproceedings{shoaran_zero-knowledge_2013,
	location = {Silicon Valley, {CA}, {USA}},
	title = {Zero-knowledge private graph summarization},
	isbn = {978-1-4799-1293-3},
	url = {http://ieeexplore.ieee.org/document/6691628/},
	doi = {10.1109/BigData.2013.6691628},
	abstract = {Graphs have become increasingly popular for modeling data in a wide variety of applications, and graph summarization is a useful technique to analyze information from large graphs. Privacy preserving mechanisms are vital to protect the privacy of individuals or institutions when releasing aggregate numbers, such as those in graph summarization. We propose privacy-aware release of graph summarization using zero-knowledge privacy ({ZKP}), a recently proposed privacy framework that is more effective than differential privacy ({DP}) for graph and social network databases. We ﬁrst deﬁne groupbased graph summaries. Next, we present techniques to compute the parameters required to design {ZKP} methods for each type of aggregate data. Then, we present an approach to achieve {ZKP} for probabilistic graphs.},
	eventtitle = {2013 {IEEE} International Conference on Big Data},
	pages = {597--605},
	booktitle = {2013 {IEEE} International Conference on Big Data},
	publisher = {{IEEE}},
	author = {Shoaran, Maryam and Thomo, Alex and Weber-Jahnke, Jens H.},
	urldate = {2020-01-05},
	date = {2013-10},
	langid = {english},
	file = {2013 - Zero-knowledge private graph summarization by Shoaran et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2013 - Zero-knowledge private graph summarization by Shoaran et al.pdf:application/pdf}
}

@article{cilibrasi_clustering_2005,
	title = {Clustering by Compression},
	volume = {51},
	abstract = {We present a new method for clustering based on compression. The method doesn’t use subject-speciﬁc features or background knowledge, and works as follows: First, we determine a parameter-free, universal, similarity distance, the normalized compression distance or {NCD} , computed from the lengths of compressed data ﬁles (singly and in pairwise concatenation). Second, we apply a hierarchical clustering method. The {NCD} is not restricted to a speciﬁc application area, and works across application area boundaries. A theoretical precursor, the normalized information distance, co-developed by one of the authors, is provably optimal. However, the optimality comes at the price of using the non-computable notion of Kolmogorov complexity. We propose axioms to capture the real-world setting, and show that the {NCD} approximates optimality. To extract a hierarchy of clusters from the distance matrix, we determine a dendrogram (binary tree) by a new quartet method and a fast heuristic to implement it. The method is implemented and available as public software, and is robust under choice of different compressors. To substantiate our claims of universality and robustness, we report evidence of successful application in areas as diverse as genomics, virology, languages, literature, music, handwritten digits, astronomy, and combinations of objects from completely different domains, using statistical, dictionary, and block sorting compressors. In genomics we presented new evidence for major questions in Mammalian evolution, based on whole-mitochondrial genomic analysis: the Eutherian orders and the Marsupionta hypothesis against the Theria hypothesis.},
	pages = {21},
	number = {4},
	journaltitle = {{IEEE} {TRANSACTIONS} {ON} {INFORMATION} {THEORY}},
	author = {Cilibrasi, Rudi and Vitanyi, Paul M B},
	date = {2005},
	langid = {english},
	file = {2005 - Clustering by Compression by Cilibrasi_Vitanyi.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2005 - Clustering by Compression by Cilibrasi_Vitanyi.pdf:application/pdf}
}

@incollection{hutchison_compression_2006,
	location = {Berlin, Heidelberg},
	title = {Compression Picks Item Sets That Matter},
	volume = {4213},
	isbn = {978-3-540-45374-1 978-3-540-46048-0},
	url = {http://link.springer.com/10.1007/11871637_59},
	abstract = {Finding a comprehensive set of patterns that truly captures the characteristics of a database is a complicated matter. Frequent item set mining attempts this, but low support levels often result in exorbitant amounts of item sets. Recently we showed that by using {MDL} we are able to select a small number of item sets that compress the data well [11]. Here we show that this small set is a good approximation of the underlying data distribution. Using the small set in a {MDL}-based classifier leads to performance on par with wellknown rule-induction and association-rule based methods. Advantages are that no parameters need to be set manually and only very few item sets are used. The classification scores indicate that selecting item sets through compression is an elegant way of mining interesting patterns that can subsequently find use in many applications.},
	pages = {585--592},
	booktitle = {Knowledge Discovery in Databases: {PKDD} 2006},
	publisher = {Springer Berlin Heidelberg},
	author = {van Leeuwen, Matthijs and Vreeken, Jilles and Siebes, Arno},
	editor = {Fürnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-01-05},
	date = {2006},
	langid = {english},
	file = {2006 - Compression Picks Item Sets That Matter by van Leeuwen et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2006 - Compression Picks Item Sets That Matter by van Leeuwen et al.pdf:application/pdf}
}

@article{chakrabarti_fully_nodate,
	title = {Fully Automatic Cross-associations},
	abstract = {Large, sparse binary matrices arise in numerous data mining applications, such as the analysis of market baskets, web graphs, social networks, co-citations, as well as information retrieval, collaborative ﬁltering, sparse matrix reordering, etc. Virtually all the popular methods for analysis of such matrices—e.g., k-means clustering, {METIS} graph partitioning, {SVD}/{PCA} and frequent itemset mining—require the user to specify various parameters, such as the number of clusters, number of principal components, number of partitions, and “support.” Choosing suitable values for such parameters is a challenging problem.},
	pages = {12},
	author = {Chakrabarti, Deepayan and Modha, Dharmendra S and Papadimitriou, Spiros and Faloutsos, Christos},
	langid = {english},
	file = {Fully Automatic Cross-associations by Chakrabarti et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/Fully Automatic Cross-associations by Chakrabarti et al.pdf:application/pdf}
}

@inproceedings{smets_odd_2011,
	title = {The Odd One Out: Identifying and Characterising Anomalies},
	isbn = {978-0-89871-992-5 978-1-61197-281-8},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611972818.69},
	doi = {10.1137/1.9781611972818.69},
	shorttitle = {The Odd One Out},
	abstract = {In many situations there exists an abundance of positive examples, but only a handful of negatives. In this paper we show how such rare cases can be identi ed and characterised in binary or transaction data.},
	eventtitle = {Proceedings of the 2011 {SIAM} International Conference on Data Mining},
	pages = {804--815},
	booktitle = {Proceedings of the 2011 {SIAM} International Conference on Data Mining},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Smets, Koen and Vreeken, Jilles},
	urldate = {2020-01-05},
	date = {2011-04-28},
	langid = {english},
	file = {2011 - The Odd One Out by Smets_Vreeken.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2011 - The Odd One Out by Smets_Vreeken.pdf:application/pdf}
}

@inproceedings{akoglu_opavion_2012,
	location = {Scottsdale, Arizona, {USA}},
	title = {{OPAvion}: mining and visualization in large graphs},
	isbn = {978-1-4503-1247-9},
	url = {http://dl.acm.org/citation.cfm?doid=2213836.2213941},
	doi = {10.1145/2213836.2213941},
	shorttitle = {{OPAvion}},
	abstract = {Given a large graph with millions or billions of nodes and edges, like a who-follows-whom Twitter graph, how do we scalably compute its statistics, summarize its patterns, spot anomalies, visualize and make sense of it? We present {OPAvion}, a graph mining system that provides a scalable, interactive workﬂow to accomplish these analysis tasks. {OPAvion} consists of three modules: (1) The Summarization module (Pegasus) operates oﬀ-line on massive, diskresident graphs and computes graph statistics, like {PageRank} scores, connected components, degree distribution, triangles, etc.; (2) The Anomaly Detection module ({OddBall}) uses graph statistics to mine patterns and spot anomalies, such as nodes with many contacts but few interactions with them (possibly telemarketers); (3) The Interactive Visualization module (Apolo) lets users incrementally explore the graph, starting with their chosen nodes or the ﬂagged anomalous nodes; then users can expand to the nodes’ vicinities, label them into categories, and thus interactively navigate the interesting parts of the graph.},
	eventtitle = {the 2012 international conference},
	pages = {717},
	booktitle = {Proceedings of the 2012 international conference on Management of Data - {SIGMOD} '12},
	publisher = {{ACM} Press},
	author = {Akoglu, Leman and Chau, Duen Horng and Kang, U. and Koutra, Danai and Faloutsos, Christos},
	urldate = {2020-01-05},
	date = {2012},
	langid = {english},
	file = {2012 - OPAvion by Akoglu et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2012 - OPAvion by Akoglu et al.pdf:application/pdf}
}

@inproceedings{mampaey_tell_2011,
	location = {San Diego, California, {USA}},
	title = {Tell me what i need to know: succinctly summarizing data with itemsets},
	isbn = {978-1-4503-0813-7},
	url = {http://dl.acm.org/citation.cfm?doid=2020408.2020499},
	doi = {10.1145/2020408.2020499},
	shorttitle = {Tell me what i need to know},
	abstract = {Data analysis is an inherently iterative process. That is, what we know about the data greatly determines our expectations, and hence, what result we would ﬁnd the most interesting. With this in mind, we introduce a well-founded approach for succinctly summarizing data with a collection of itemsets; using a probabilistic maximum entropy model, we iteratively ﬁnd the most interesting itemset, and in turn update our model of the data accordingly. As we only include itemsets that are surprising with regard to the current model, the summary is guaranteed to be both descriptive and non-redundant. The algorithm that we present can either mine the top-k most interesting itemsets, or use the Bayesian Information Criterion to automatically identify the model containing only the itemsets most important for describing the data. Or, in other words, it will ‘tell you what you need to know’. Experiments on synthetic and benchmark data show that the discovered summaries are succinct, and correctly identify the key patterns in the data. The models they form attain high likelihoods, and inspection shows that they summarize the data well with increasingly speciﬁc, yet non-redundant itemsets.},
	eventtitle = {the 17th {ACM} {SIGKDD} international conference},
	pages = {573},
	booktitle = {Proceedings of the 17th {ACM} {SIGKDD} international conference on Knowledge discovery and data mining - {KDD} '11},
	publisher = {{ACM} Press},
	author = {Mampaey, Michael and Tatti, Nikolaj and Vreeken, Jilles},
	urldate = {2020-01-05},
	date = {2011},
	langid = {english},
	file = {2011 - Tell me what i need to know by Mampaey et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2011 - Tell me what i need to know by Mampaey et al.pdf:application/pdf}
}

@inproceedings{prakash_spotting_2012,
	location = {Brussels, Belgium},
	title = {Spotting Culprits in Epidemics: How Many and Which Ones?},
	isbn = {978-1-4673-4649-8 978-0-7695-4905-7},
	url = {http://ieeexplore.ieee.org/document/6413787/},
	doi = {10.1109/ICDM.2012.136},
	shorttitle = {Spotting Culprits in Epidemics},
	abstract = {Given a snapshot of a large graph, in which an infection has been spreading for some time, can we identify those nodes from which the infection started to spread? In other words, can we reliably tell who the culprits are? In this paper we answer this question afﬁrmatively, and give an efﬁcient method called {NETSLEUTH} for the well-known {SusceptibleInfected} virus propagation model. Essentially, we are after that set of seed nodes that best explain the given snapshot. We propose to employ the Minimum Description Length principle to identify the best set of seed nodes and virus propagation ripple, as the one by which we can most succinctly describe the infected graph.},
	eventtitle = {2012 {IEEE} 12th International Conference on Data Mining ({ICDM})},
	pages = {11--20},
	booktitle = {2012 {IEEE} 12th International Conference on Data Mining},
	publisher = {{IEEE}},
	author = {Prakash, B. Aditya and Vreeken, Jilles and Faloutsos, Christos},
	urldate = {2020-01-05},
	date = {2012-12},
	langid = {english},
	file = {2012 - Spotting Culprits in Epidemics by Prakash et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2012 - Spotting Culprits in Epidemics by Prakash et al.pdf:application/pdf}
}

@article{kivela_multilayer_2014,
	title = {Multilayer networks},
	volume = {2},
	issn = {2051-1310, 2051-1329},
	url = {https://academic.oup.com/comnet/article-lookup/doi/10.1093/comnet/cnu016},
	doi = {10.1093/comnet/cnu016},
	abstract = {Most real and engineered systems include multiple subsystems and layers of connectivity, and it is important to take such features into account to try to improve our understanding of these systems. It is thus necessary to generalize “traditional" network theory by developing (and validating) a framework and associated tools to study multilayer systems in a comprehensive fashion. The origins of such eﬀorts date back several decades and arose in multiple disciplines, and now the study of multilayer networks has become one of the most important directions in network science. In this paper, we discuss the history of multilayer networks (and related concepts) and review the exploding body of work on such networks. To unify the disparate terminology in the large body of recent work, we discuss a general framework for multilayer networks, construct a dictionary of terminology to relate the numerous existing concepts to each other, and provide a thorough discussion that compares, contrasts, and translates between related notions such as multilayer networks, multiplex networks, interdependent networks, networks of networks, and many others. We also survey and discuss existing data sets that can be represented as multilayer networks. We review attempts to generalize single-layer-network diagnostics to multilayer networks. We also discuss the rapidly expanding research on multilayer-network models and notions like community detection, connected components, tensor decompositions, and various types of dynamical processes on multilayer networks. We conclude with a summary and an outlook.},
	pages = {203--271},
	number = {3},
	journaltitle = {Journal of Complex Networks},
	shortjournal = {Journal of Complex Networks},
	author = {Kivela, M. and Arenas, A. and Barthelemy, M. and Gleeson, J. P. and Moreno, Y. and Porter, M. A.},
	urldate = {2020-01-05},
	date = {2014-09-01},
	langid = {english},
	file = {2014 - Multilayer networks by Kivela et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2014 - Multilayer networks by Kivela et al.pdf:application/pdf}
}

@inproceedings{leskovec_graphs_2005,
	location = {Chicago, Illinois, {USA}},
	title = {Graphs over time: densification laws, shrinking diameters and possible explanations},
	isbn = {978-1-59593-135-1},
	url = {http://portal.acm.org/citation.cfm?doid=1081870.1081893},
	doi = {10.1145/1081870.1081893},
	shorttitle = {Graphs over time},
	abstract = {How do real graphs evolve over time? What are “normal” growth patterns in social, technological, and information networks? Many studies have discovered patterns in static graphs, identifying properties in a single snapshot of a large network, or in a very small number of snapshots; these include heavy tails for in- and out-degree distributions, communities, small-world phenomena, and others. However, given the lack of information about network evolution over long periods, it has been hard to convert these ﬁndings into statements about trends over time.},
	eventtitle = {Proceeding of the eleventh {ACM} {SIGKDD} international conference},
	pages = {177},
	booktitle = {Proceeding of the eleventh {ACM} {SIGKDD} international conference on Knowledge discovery in data mining  - {KDD} '05},
	publisher = {{ACM} Press},
	author = {Leskovec, Jure and Kleinberg, Jon and Faloutsos, Christos},
	urldate = {2020-01-05},
	date = {2005},
	langid = {english},
	file = {2005 - Graphs over time by Leskovec et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2005 - Graphs over time by Leskovec et al.pdf:application/pdf}
}

@data{DVN/5H4TDI_2018,
author = {Han, Xueyuan},
publisher = {Harvard Dataverse},
title = "{Hour-Long Wget Benign Dataset (Base Graph)}",
year = {2018},
version = {V1},
doi = {10.7910/DVN/5H4TDI},
url = {https://doi.org/10.7910/DVN/5H4TDI}
}

@article{leskovec_graph_2007,
	title = {Graph evolution: Densification and shrinking diameters},
	volume = {1},
	issn = {15564681},
	url = {http://portal.acm.org/citation.cfm?doid=1217299.1217301},
	doi = {10.1145/1217299.1217301},
	shorttitle = {Graph evolution},
	pages = {2--es},
	number = {1},
	journaltitle = {{ACM} Transactions on Knowledge Discovery from Data},
	shortjournal = {{ACM} Trans. Knowl. Discov. Data},
	author = {Leskovec, Jure and Kleinberg, Jon and Faloutsos, Christos},
	urldate = {2020-02-17},
	date = {2007-03-01},
	langid = {english},
	file = {2007 - Graph evolution by Leskovec et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2007 - Graph evolution by Leskovec et al.pdf:application/pdf;Leskovec et al. - 2007 - Graph evolution Densification and shrinking diame.pdf:/Users/ivantha/Zotero/storage/Q2RABB6I/Leskovec et al. - 2007 - Graph evolution Densification and shrinking diame.pdf:application/pdf}
}

@article{gehrke_overview_2003,
	title = {Overview of the 2003 {KDD} Cup},
	volume = {5},
	issn = {19310145},
	url = {http://portal.acm.org/citation.cfm?doid=980972.980992},
	doi = {10.1145/980972.980992},
	abstract = {This paper surveys the 2003 {KDD} Cup, a competition held in conjunction with the Ninth {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining ({KDD}) in August 2003. The competition focused on mining the complex real-life social network inherent in the e-print {arXiv} ({arXiv}.org). We describe the four {KDD} Cup tasks: citation prediction, download prediction, data cleaning, and an open task.},
	pages = {149},
	number = {2},
	journaltitle = {{ACM} {SIGKDD} Explorations Newsletter},
	shortjournal = {{SIGKDD} Explor. Newsl.},
	author = {Gehrke, Johannes and Ginsparg, Paul and Kleinberg, Jon},
	urldate = {2020-02-17},
	date = {2003-12-01},
	langid = {english},
	file = {2003 - Overview of the 2003 KDD Cup by Gehrke et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2003 - Overview of the 2003 KDD Cup by Gehrke et al.pdf:application/pdf}
}

@online{noauthor_snap_nodate_email,
	title = {{SNAP}: Network datasets: {EU} email network},
	url = {https://snap.stanford.edu/data/email-EuAll.html},
	urldate = {2020-02-18},
	file = {SNAP\: Network datasets\: EU email network:/Users/ivantha/Zotero/storage/2SE249LZ/email-EuAll.html:text/html}
}

@online{noauthor_snap_nodate_hep,
	title = {{SNAP}: Network datasets: High-energy physics Phenomenology citation network},
	url = {https://snap.stanford.edu/data/cit-HepPh.html},
	urldate = {2020-02-18},
	file = {SNAP\: Network datasets\: High-energy physics Phenomenology citation network:/Users/ivantha/Zotero/storage/U26ZYQPJ/cit-HepPh.html:text/html}
}

@article{bollobas_degree_2001,
	title = {The degree sequence of a scale-free random graph process: Degree Sequence of a Random Graph},
	volume = {18},
	issn = {10429832},
	url = {http://doi.wiley.com/10.1002/rsa.1009},
	doi = {10.1002/rsa.1009},
	shorttitle = {The degree sequence of a scale-free random graph process},
	pages = {279--290},
	number = {3},
	journaltitle = {Random Structures \& Algorithms},
	shortjournal = {Random Struct. Alg.},
	author = {Bollobas, Bela and Riordan, Oliver and Spencer, Joel and Tusnády, Gabor},
	urldate = {2020-02-18},
	date = {2001-05},
	langid = {english},
	file = {2001 - The degree sequence of a scale-free random graph process by Bollobás et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2001 - The degree sequence of a scale-free random graph process by Bollobás et al.pdf:application/pdf}
}

@article{wang_random_2006,
	title = {Random pseudofractal scale-free networks with small-world effect},
	volume = {53},
	issn = {1434-6036},
	url = {https://doi.org/10.1140/epjb/e2006-00389-0},
	doi = {10.1140/epjb/e2006-00389-0},
	abstract = {A random pseudofractal network ({RPN}) is generated by arecursive growing rule. The {RPN} is of the scale-free feature andsmall-world effect. We obtain the theoretical results of power-lawexponent γ=3, clustering coefficient C=3π2-19≈0.74, and a proof that the mean distance increases no faster thanln N, where N is the network size. These results agree withthe numerical simulation very well. In particular, we explain theproperty of growth and preferential attachment in {RPNs}. And theproperties of a class of general {RPNs} are discussed in the end.},
	pages = {361--366},
	number = {3},
	journaltitle = {The European Physical Journal B - Condensed Matter and Complex Systems},
	shortjournal = {Eur. Phys. J. B},
	author = {Wang, L. and Du, F. and Dai, H. P. and Sun, Y. X.},
	urldate = {2020-02-18},
	date = {2006-10-01},
	langid = {english}
}

@article{fagin_comparing_2003,
	title = {Comparing Top k Lists},
	volume = {17},
	issn = {0895-4801, 1095-7146},
	url = {http://epubs.siam.org/doi/10.1137/S0895480102412856},
	doi = {10.1137/S0895480102412856},
	abstract = {Motivated by several applications, we introduce various distance measures between “top k lists.” Some of these distance measures are metrics, while others are not. For each of these latter distance measures, we show that they are “almost” a metric in the following two seemingly unrelated aspects: (i) they satisfy a relaxed version of the polygonal (hence, triangle) inequality, and (ii) there is a metric with positive constant multiples that bound our measure above and below. This is not a coincidence—we show that these two notions of almost being a metric are same. Based on the second notion, we deﬁne two distance measures to be equivalent if they are bounded above and below by constant multiples of each other. We thereby identify a large and robust equivalence class of distance measures.},
	pages = {134--160},
	number = {1},
	journaltitle = {{SIAM} Journal on Discrete Mathematics},
	shortjournal = {{SIAM} J. Discrete Math.},
	author = {Fagin, Ronald and Kumar, Ravi and Sivakumar, D.},
	urldate = {2020-02-19},
	date = {2003-01},
	langid = {english},
	file = {2003 - Comparing Top k Lists by Fagin et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2003 - Comparing Top k Lists by Fagin et al.pdf:application/pdf}
}

@inproceedings{kumarage_efficient_2017,
	location = {Peradeniya},
	title = {An efficient query platform for streaming and dynamic natural graphs},
	isbn = {978-1-5386-1674-1 978-1-5386-1676-5},
	url = {http://ieeexplore.ieee.org/document/8300418/},
	doi = {10.1109/ICIINFS.2017.8300418},
	abstract = {Massive scale data streaming is now prevalent and can be used to dynamically build large graphs which are then efﬁciently analyzable for insightful information. In situations where real time analytics is required approximate outcomes within time bounds may be desirable. We have identiﬁed graph summarization and {TCM} sketching in particular as a good technique for graph summarization for streaming data. {TCM} sketching provides a set of metrics such as Average Relative Error, Number of Effective Queries, Effectiveness of Effective Queries and Confusion Matrix of queries on streaming graphs. We then propose extensions to the {TCM} model for automatic sketch creation while the graph is being constructed and evaluate the approach with different sketch creation policies and query combinations. The proposed query framework works well with streaming graphs with 80\% to 90\% query efﬁciency and ±33 deviation from exact results.},
	eventtitle = {2017 {IEEE} International Conference on Industrial and Information Systems ({ICIIS})},
	pages = {1--6},
	booktitle = {2017 {IEEE} International Conference on Industrial and Information Systems ({ICIIS})},
	publisher = {{IEEE}},
	author = {Kumarage, Milindu Sanoj and Horawalavithana, Yasanka and Ranasinghe, D.N.},
	urldate = {2020-02-19},
	date = {2017-12},
	langid = {english},
	file = {2017 - An efficient query platform for streaming and dynamic natural graphs by Kumarage et al.pdf:/Users/ivantha/Google Drive/Zotero/Realtime Property Evaluation of Large Streaming Graphs/2017 - An efficient query platform for streaming and dynamic natural graphs by Kumarage et al2.pdf:application/pdf}
}